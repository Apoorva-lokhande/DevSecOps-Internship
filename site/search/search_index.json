{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Project Title : Managing a DevSecOps Pipeline with Secure Development and Operations Author : Apoorva Lokhande Mentors : Akash Mahajan , Sunesh Govindaraj , Ayush Priya , Priyam Singh . This report documents the tasks that I performed as a DevSecOps Engineer at Appsecco . This documentation comprises of my solutions to various tasks alongside different notes on issues I confronted and their correction measures.","title":"Introduction"},{"location":"Complete-pipeline/","text":"","title":"Complete Pipeline"},{"location":"DAST/","text":"Dynamic Analysis Dynamic analysis is the process of testing and evaluating a program while software is running. Also referred to as dynamic code scanning, dynamic analysis improves the diagnosis and correction of bugs, memory issues, and crashes of an application during its execution. Why is Dynamic Analysis Needed? Dynamic application security testing (DAST) is a method of AppSec testing that examines an application while it\u2019s running, without knowledge of the application\u2019s internal interactions or designs at the system level, and with no access or visibility into the source program. This \u201cblack box\u201d testing looks at an application from the outside in, examines its running state, and observes its responses to simulated attacks made by the tool. An application\u2019s responses to these simulations help determine whether the application is vulnerable and could be susceptible to a real malicious attack. Static Vs Dynamic Analysis Static code analysis is done by examining the code without the need to execute the program. The process provides an understanding of the code structure and can help ensure that the code adheres to industry standards. All code is scanned to check for any vulnerabilities and ensure the code is validated. Dynamic analysis adopts the opposite approach and is executed while a program is in operation. Dynamic analysis performs continuous and concurrent risk assessments, searching for vulnerabilities within web applications and speeding interventions. OWASP ZAP ZAP is an open source tool which is offered by OWASP (Open Web Application Security Project), for penetration testing of your website/web application. It helps you find the security vulnerabilities in your application. ZAP creates a proxy server and makes your website traffic pass through that server. It comprises of auto scanners that help you intercept the vulnerabilities in your website. I followed the official documentation and pulled the ZAP image from docker: docker pull owasp/zap2docker-stable I got an permission denied error, and resolved it by changing the permissions as below: sudo chmod 666 /var/run/docker.sock","title":"Dynamic Analysis"},{"location":"DAST/#dynamic-analysis","text":"Dynamic analysis is the process of testing and evaluating a program while software is running. Also referred to as dynamic code scanning, dynamic analysis improves the diagnosis and correction of bugs, memory issues, and crashes of an application during its execution.","title":"Dynamic Analysis"},{"location":"DAST/#why-is-dynamic-analysis-needed","text":"Dynamic application security testing (DAST) is a method of AppSec testing that examines an application while it\u2019s running, without knowledge of the application\u2019s internal interactions or designs at the system level, and with no access or visibility into the source program. This \u201cblack box\u201d testing looks at an application from the outside in, examines its running state, and observes its responses to simulated attacks made by the tool. An application\u2019s responses to these simulations help determine whether the application is vulnerable and could be susceptible to a real malicious attack.","title":"Why is Dynamic Analysis Needed?"},{"location":"DAST/#static-vs-dynamic-analysis","text":"Static code analysis is done by examining the code without the need to execute the program. The process provides an understanding of the code structure and can help ensure that the code adheres to industry standards. All code is scanned to check for any vulnerabilities and ensure the code is validated. Dynamic analysis adopts the opposite approach and is executed while a program is in operation. Dynamic analysis performs continuous and concurrent risk assessments, searching for vulnerabilities within web applications and speeding interventions.","title":"Static Vs Dynamic Analysis"},{"location":"DAST/#owasp-zap","text":"ZAP is an open source tool which is offered by OWASP (Open Web Application Security Project), for penetration testing of your website/web application. It helps you find the security vulnerabilities in your application. ZAP creates a proxy server and makes your website traffic pass through that server. It comprises of auto scanners that help you intercept the vulnerabilities in your website. I followed the official documentation and pulled the ZAP image from docker: docker pull owasp/zap2docker-stable I got an permission denied error, and resolved it by changing the permissions as below: sudo chmod 666 /var/run/docker.sock","title":"OWASP ZAP"},{"location":"Problem-statements/","text":"","title":"Problem statements"},{"location":"Resources/","text":"","title":"Resources"},{"location":"SAST/","text":"Static Application Security Testing(SAST) SAST is a testing methodology that analyses source code, byte code and binaries for bugs and design errors to find security vulnerabilities , before the application is compiled. SAST does not require a working application and can take place without code being executed. It helps developers identify vulnerabilities in the initial stages of development and quickly resolve issues without breaking builds or passing on vulnerabilities to the final release of the application. SAST Tools for Node.js Applications As given the name Damn Vulnerable Nodejs Application, it is quite obvious to figure the tech stack used, Nodejs is the server-side language used along with a SQL database. The following are the tools used to perform static analysis on Nodejs applications with steps to install and configure them with Jenkins. njsscan njsscan is a open source static security code scanner for Node.js applications. Finds insecure paatterns in Node.js code and HTML templates. The tool is written in python, hence we need to install it using pip3: pip3 install njsscan NOTE: I got an error while installing through njsscan, I entered into the root directory and installed it, which worked for me or you can also create a virtual environment and install it. After installing, I executed the tool via shell script: mkdir reports njsscan -o ~/reports/nodejsscan-report.json --json ./dvna I referred the document which provides us command line options . Later, I added the script in the jenkinsfile with the following syntax: njsscan pipeline AuditJS Audits JavaScript is a SAST tool which uses OSS Index v3 REST API to identify known vulnerabilities and outdated package versions. To install npm and nodejs in dvna container in production server, I followed the commandsas given below, the package versions are: npm v6.14.14 and nodejs v14.17.4. sudo apt update sudo curl -sL https://deb.nodesource.com/setup_14.x | sudo -E bash - sudo apt install -y nodejs Install auditjs using npm: sudo npm install -g auditjs Scan the directory which holds the files for DVNA and store the scan result in ~/reports/auditjs-report. auditjs ossi > ~/reports/auditjs-report ./dvna AuditJS pipeline SAST Pipeline sudo dhclient enp0s3","title":"Static Analysis"},{"location":"SAST/#static-application-security-testingsast","text":"SAST is a testing methodology that analyses source code, byte code and binaries for bugs and design errors to find security vulnerabilities , before the application is compiled. SAST does not require a working application and can take place without code being executed. It helps developers identify vulnerabilities in the initial stages of development and quickly resolve issues without breaking builds or passing on vulnerabilities to the final release of the application.","title":"Static Application Security Testing(SAST)"},{"location":"SAST/#sast-tools-for-nodejs-applications","text":"As given the name Damn Vulnerable Nodejs Application, it is quite obvious to figure the tech stack used, Nodejs is the server-side language used along with a SQL database. The following are the tools used to perform static analysis on Nodejs applications with steps to install and configure them with Jenkins.","title":"SAST Tools for Node.js Applications"},{"location":"SAST/#njsscan","text":"njsscan is a open source static security code scanner for Node.js applications. Finds insecure paatterns in Node.js code and HTML templates. The tool is written in python, hence we need to install it using pip3: pip3 install njsscan NOTE: I got an error while installing through njsscan, I entered into the root directory and installed it, which worked for me or you can also create a virtual environment and install it. After installing, I executed the tool via shell script: mkdir reports njsscan -o ~/reports/nodejsscan-report.json --json ./dvna I referred the document which provides us command line options . Later, I added the script in the jenkinsfile with the following syntax:","title":"njsscan"},{"location":"SAST/#njsscan-pipeline","text":"","title":"njsscan pipeline"},{"location":"SAST/#auditjs","text":"Audits JavaScript is a SAST tool which uses OSS Index v3 REST API to identify known vulnerabilities and outdated package versions. To install npm and nodejs in dvna container in production server, I followed the commandsas given below, the package versions are: npm v6.14.14 and nodejs v14.17.4. sudo apt update sudo curl -sL https://deb.nodesource.com/setup_14.x | sudo -E bash - sudo apt install -y nodejs Install auditjs using npm: sudo npm install -g auditjs Scan the directory which holds the files for DVNA and store the scan result in ~/reports/auditjs-report. auditjs ossi > ~/reports/auditjs-report ./dvna","title":"AuditJS"},{"location":"SAST/#auditjs-pipeline","text":"","title":"AuditJS pipeline"},{"location":"SAST/#sast-pipeline","text":"sudo dhclient enp0s3","title":"SAST Pipeline"},{"location":"SCA/","text":"What is SCA? Software composition analysis (SCA) is an automated process that identifies the open source software in a codebase. This analysis is performed to evaluate security, license compliance, and code quality. In a modern DevSecOps environment, SCA has galvanized the shift left paradigm. Earlier and continuous SCA testing has enabled developers and security teams to drive productivity without compromising security and quality. How does SCA work? SCA tools can discover all related components, their supporting libraries, and their direct and indirect dependencies. SCA tools can also detect software licenses, deprecated dependencies, as well as vulnerabilities and potential exploits. The scanning process generates a component inventory or software bill of materials (SBoM) , providing a complete inventory of a project\u2019s software assets which is then compared against a variety of databases, these databases hold information regarding known and common vulnerabilities. Software bill of materials There are four levels of details for SBoMs: Licenses Modules Patch levels Backports Most of the discussion about SBoMs is roughly at the license level CycloneDX To generate the SBoM for DVNA, we are using a tool called CycloneDX. According to the documentation CycloneDX is a module for Node.js creates a valid CycloneDX SBoM containing an aggregate of all project dependencies. Installation Here, I installed CycloneDX's Node module with NPM by using the command: npm install -g @cyclonedx/bom Later, I ran CycloneD","title":"What is SCA?"},{"location":"SCA/#what-is-sca","text":"Software composition analysis (SCA) is an automated process that identifies the open source software in a codebase. This analysis is performed to evaluate security, license compliance, and code quality. In a modern DevSecOps environment, SCA has galvanized the shift left paradigm. Earlier and continuous SCA testing has enabled developers and security teams to drive productivity without compromising security and quality.","title":"What is SCA?"},{"location":"SCA/#how-does-sca-work","text":"SCA tools can discover all related components, their supporting libraries, and their direct and indirect dependencies. SCA tools can also detect software licenses, deprecated dependencies, as well as vulnerabilities and potential exploits. The scanning process generates a component inventory or software bill of materials (SBoM) , providing a complete inventory of a project\u2019s software assets which is then compared against a variety of databases, these databases hold information regarding known and common vulnerabilities.","title":"How does SCA work?"},{"location":"SCA/#software-bill-of-materials","text":"There are four levels of details for SBoMs: Licenses Modules Patch levels Backports Most of the discussion about SBoMs is roughly at the license level","title":"Software bill of materials"},{"location":"SCA/#cyclonedx","text":"To generate the SBoM for DVNA, we are using a tool called CycloneDX. According to the documentation CycloneDX is a module for Node.js creates a valid CycloneDX SBoM containing an aggregate of all project dependencies.","title":"CycloneDX"},{"location":"SCA/#installation","text":"Here, I installed CycloneDX's Node module with NPM by using the command: npm install -g @cyclonedx/bom Later, I ran CycloneD","title":"Installation"},{"location":"Source-Code-Quality-Analysis/","text":"Source Code Quality Analysis Source Code Linting Lint, or a linter, is a source code analysis tool used to flag programming errors, bugs, stylistic errors, and suspicious constructs. Linter's are used to generate reports about the code quality by either invoking a built-in functionality or writing a reporting wrapper arround the tool to resolve the identified issues. Linting tools for DVNA DVNA is a Nodejs application and hence, I used JSHint and ESLint as the linter. JSHint scans your program's source code and reports about commonly made mistakes and potential bugs. The potential problem could be a syntax error, a bug due to implicit type conversion, a leaking variable, or any of the other problems that JSHint looks for and it is a command-line utility, I can easily integrate it into my CI pipeline with Jenkins. Integrating JSHint with Jenkins pipeline I installed it globally with NPM using the following command: sudo npm install -g jshint Run the jshint command with the aplication/project directory to scan all the .js files as given below: jshint ~/dvna > ~/report/jshint-report To restrict the scan to only .js and .ejs files, use a find command. We will further exclude all files in the node_modules directory. jshint $(find ~/app -type f -name \"*.js\" -o -name \"*.ejs\" | grep -v node_modules) > ~/reports/jshint-report JSHint Pipeline ESLint ESLint is a static code analysis tool for identifying problematic patterns found in JavaScript code. ESLint covers both code quality and coding style issues.","title":"Source Code Quality Analysis"},{"location":"Source-Code-Quality-Analysis/#source-code-quality-analysis","text":"","title":"Source Code Quality Analysis"},{"location":"Source-Code-Quality-Analysis/#source-code-linting","text":"Lint, or a linter, is a source code analysis tool used to flag programming errors, bugs, stylistic errors, and suspicious constructs. Linter's are used to generate reports about the code quality by either invoking a built-in functionality or writing a reporting wrapper arround the tool to resolve the identified issues.","title":"Source Code Linting"},{"location":"Source-Code-Quality-Analysis/#linting-tools-for-dvna","text":"DVNA is a Nodejs application and hence, I used JSHint and ESLint as the linter. JSHint scans your program's source code and reports about commonly made mistakes and potential bugs. The potential problem could be a syntax error, a bug due to implicit type conversion, a leaking variable, or any of the other problems that JSHint looks for and it is a command-line utility, I can easily integrate it into my CI pipeline with Jenkins.","title":"Linting tools for DVNA"},{"location":"Source-Code-Quality-Analysis/#integrating-jshint-with-jenkins-pipeline","text":"I installed it globally with NPM using the following command: sudo npm install -g jshint Run the jshint command with the aplication/project directory to scan all the .js files as given below: jshint ~/dvna > ~/report/jshint-report To restrict the scan to only .js and .ejs files, use a find command. We will further exclude all files in the node_modules directory. jshint $(find ~/app -type f -name \"*.js\" -o -name \"*.ejs\" | grep -v node_modules) > ~/reports/jshint-report","title":"Integrating JSHint with Jenkins pipeline"},{"location":"Source-Code-Quality-Analysis/#jshint-pipeline","text":"","title":"JSHint Pipeline"},{"location":"Source-Code-Quality-Analysis/#eslint","text":"ESLint is a static code analysis tool for identifying problematic patterns found in JavaScript code. ESLint covers both code quality and coding style issues.","title":"ESLint"},{"location":"Source-code-aulaiity-analysis/","text":"Source Code Quality Analysis Source Code Linting Lint, or a linter, is a source code analysis tool used to flag programming errors, bugs, stylistic errors, and suspicious constructs. Linter's are used to generate reports about the code quality by either invoking a built-in functionality or writing a reporting wrapper arround the tool to resolve the identified issues. Linting tools for DVNA DVNA is a Nodejs application and hence, I used JSHint and ESLint as the linter. JSHint scans your program's source code and reports about commonly made mistakes and potential bugs. The potential problem could be a syntax error, a bug due to implicit type conversion, a leaking variable, or any of the other problems that JSHint looks for and it is a command-line utility, I can easily integrate it into my CI pipeline with Jenkins. Integrating JSHint with Jenkins pipeline I installed it globally with NPM using the following command: sudo npm install -g jshint Run the jshint command with the aplication/project directory to scan all the .js files as given below: jshint ~/dvna > ~/report/jshint-report To restrict the scan to only .js and .ejs files, use a find command. We will further exclude all files in the node_modules directory. jshint $(find ~/app -type f -name \"*.js\" -o -name \"*.ejs\" | grep -v node_modules) > ~/reports/jshint-report JSHint Pipeline ESLint ESLint is a static code analysis tool for identifying problematic patterns found in JavaScript code. ESLint covers both code quality and coding style issues.","title":"Source Code Quality Analysis"},{"location":"Source-code-aulaiity-analysis/#source-code-quality-analysis","text":"","title":"Source Code Quality Analysis"},{"location":"Source-code-aulaiity-analysis/#source-code-linting","text":"Lint, or a linter, is a source code analysis tool used to flag programming errors, bugs, stylistic errors, and suspicious constructs. Linter's are used to generate reports about the code quality by either invoking a built-in functionality or writing a reporting wrapper arround the tool to resolve the identified issues.","title":"Source Code Linting"},{"location":"Source-code-aulaiity-analysis/#linting-tools-for-dvna","text":"DVNA is a Nodejs application and hence, I used JSHint and ESLint as the linter. JSHint scans your program's source code and reports about commonly made mistakes and potential bugs. The potential problem could be a syntax error, a bug due to implicit type conversion, a leaking variable, or any of the other problems that JSHint looks for and it is a command-line utility, I can easily integrate it into my CI pipeline with Jenkins.","title":"Linting tools for DVNA"},{"location":"Source-code-aulaiity-analysis/#integrating-jshint-with-jenkins-pipeline","text":"I installed it globally with NPM using the following command: sudo npm install -g jshint Run the jshint command with the aplication/project directory to scan all the .js files as given below: jshint ~/dvna > ~/report/jshint-report To restrict the scan to only .js and .ejs files, use a find command. We will further exclude all files in the node_modules directory. jshint $(find ~/app -type f -name \"*.js\" -o -name \"*.ejs\" | grep -v node_modules) > ~/reports/jshint-report","title":"Integrating JSHint with Jenkins pipeline"},{"location":"Source-code-aulaiity-analysis/#jshint-pipeline","text":"","title":"JSHint Pipeline"},{"location":"Source-code-aulaiity-analysis/#eslint","text":"ESLint is a static code analysis tool for identifying problematic patterns found in JavaScript code. ESLint covers both code quality and coding style issues.","title":"ESLint"},{"location":"Working-of-pipeline/","text":"Working of pipeline To start creating the Jenkins pipeline, login into the jenkin web interface. In the Dashboard , create a New Item and enter a item name (e.g. dvna-pipeline ) and select pipeline and click OK . It was redirected to the configuration page. Here: Under general section: Gave description of the application being deployed. I checked the Discard old builds as they keep metadata related to old builds. Under pipeline section, I selected the defination dropdown to Pipeline script from SCM . In SCM dropdown I selected GIT , and gave the repository URL . Click Save to save and aplly the configurations. Go to Dashboard -> dvna-pipeline -> build now -> console output . Jenkinsfile Jenkinsfile is a text file that contains the definition of a Jenkins Pipeline and is checked into source control.The following are the contents of the Jenkinsfile which implements a continuous delivery pipeline: pipeline { agent any stages { stage ('Initialization') { steps { sh 'echo \"Starting the build!\"' } } stage ('Build') { environment { MYSQL_USER=\"dvna\" MYSQL_DATABASE=\"dvna\" MYSQL_PASSWORD=\"Prlokhande_5398\" MYSQL_RANDOM_ROOT_PASSWORD=\"yes\" MYSQL_HOST=\"mysql-db\" MYSQL_PORT=3306 } steps { sh 'echo \"MYSQL_USER=$MYSQL_USER\\nMYSQL_DATABASE=$MYSQL_DATABASE\\nMYSQL_PASSWORD=$MYSQL_PASSWORD\\nMYSQL_RANDOM_ROOT_PASSWORD=$MYSQL_RANDOM_ROOT_PASSWORD\\nMYSQL_HOST=$MYSQL_HOST\\nMYSQL_PORT=$MYSQL_PORT\" > ~/vars.env' sh 'docker run --rm -d --name dvna-mysql --env-file ~/vars.env mysql:5.7 tail -f /dev/null' sh 'docker run --rm -d --name dvna-app --env-file ~/vars.env --link dvna-mysql:mysql-db -p 9090:9090 appsecco/dvna' sh 'docker cp dvna-app:/app/ ~/' } } stage ('Remove DVNA from Jenkins') { steps { sh 'rm -rf ~/app' sh 'docker stop dvna-app && docker stop dvna-mysql' sh 'docker rmi appsecco/dvna' } } stage ('Deploy DVNA to Production') { steps { sh 'ssh -tt -o StrictHostKeyChecking=no prod-vm@192.168.1.55 \"docker stop dvna-app && docker stop dvna-mysql && docker rm dvna-app && docker rm dvna-mysql && docker rmi appsecco/dvna || true\"' sh 'scp ~/vars.env prod-vm@192.168.1.55:~/' sh 'ssh -tt -o StrictHostKeyChecking=no prod-vm@192.168.1.55 \"docker run -d --name dvna-mysql --env-file ~/vars.env mysql:5.7 tail -f /dev/null\"' sh 'ssh -tt -o StrictHostKeyChecking=no prod-vm@192.168.1.55 \"docker run -d --name dvna-app --env-file ~/vars.env --link dvna-mysql:mysql-db -p 9090:9090 appsecco/dvna\"' } } } } pipeline - Constitutes the entire definition of the pipeline. agent - Is used to choose the way the Jenkins instance(s) are used to run the pipeline. The any keyword defines that Jenkins should - allocate any available agent (an instance of Jenkins/a slave/the master instance) to execute the pipeline. stages - Consists of all the stages/jobs to be performed during the execution of the pipeline. stage - Specify the task to be performed. steps - This block defines actions to be performed within a particular stage. sh - Used to execute shell commands through Jenkins. Stages The pipeline is divided into various stages based on the operations being performed, which are as follows: Initialization This is the first stage which is used to just display the start of the building stage. Build This stage contains the environment variables, in which vars.env file is created and for dvna-mysql container. dvna-app and dvna-mysql containers will run and will be copied into the home directory. Static and Dynamic Analysis All the stages that follow the Build Stage, except for the last two stages, are for performing static analysis and dynamic analysis on DVNA and later being stored in a folder reports in jenkins home directory. Remove DVNA from Jenkins After the scans are complete, the containers running in Jenkins VM are stopped and removed. Since we're working with a containerized application (DVNA), we need to perform tests on the latest available image on DockerHub. Hence, we remove the existing local appsecco/dvna docker image to avoid running a container with older release of the application image. On the other hand, you don't need to remove the mysql:5.7 image, since we require v5.7 and not the latest version. Deployment Finally, the satge deploy to dvna , operations are performed on VM over SSH which was configured previously. The two containers, dvna-app and dvna-mysql are run and successfully deployed.","title":"Working of pipeline"},{"location":"Working-of-pipeline/#working-of-pipeline","text":"To start creating the Jenkins pipeline, login into the jenkin web interface. In the Dashboard , create a New Item and enter a item name (e.g. dvna-pipeline ) and select pipeline and click OK . It was redirected to the configuration page. Here: Under general section: Gave description of the application being deployed. I checked the Discard old builds as they keep metadata related to old builds. Under pipeline section, I selected the defination dropdown to Pipeline script from SCM . In SCM dropdown I selected GIT , and gave the repository URL . Click Save to save and aplly the configurations. Go to Dashboard -> dvna-pipeline -> build now -> console output .","title":"Working of pipeline"},{"location":"Working-of-pipeline/#jenkinsfile","text":"Jenkinsfile is a text file that contains the definition of a Jenkins Pipeline and is checked into source control.The following are the contents of the Jenkinsfile which implements a continuous delivery pipeline: pipeline { agent any stages { stage ('Initialization') { steps { sh 'echo \"Starting the build!\"' } } stage ('Build') { environment { MYSQL_USER=\"dvna\" MYSQL_DATABASE=\"dvna\" MYSQL_PASSWORD=\"Prlokhande_5398\" MYSQL_RANDOM_ROOT_PASSWORD=\"yes\" MYSQL_HOST=\"mysql-db\" MYSQL_PORT=3306 } steps { sh 'echo \"MYSQL_USER=$MYSQL_USER\\nMYSQL_DATABASE=$MYSQL_DATABASE\\nMYSQL_PASSWORD=$MYSQL_PASSWORD\\nMYSQL_RANDOM_ROOT_PASSWORD=$MYSQL_RANDOM_ROOT_PASSWORD\\nMYSQL_HOST=$MYSQL_HOST\\nMYSQL_PORT=$MYSQL_PORT\" > ~/vars.env' sh 'docker run --rm -d --name dvna-mysql --env-file ~/vars.env mysql:5.7 tail -f /dev/null' sh 'docker run --rm -d --name dvna-app --env-file ~/vars.env --link dvna-mysql:mysql-db -p 9090:9090 appsecco/dvna' sh 'docker cp dvna-app:/app/ ~/' } } stage ('Remove DVNA from Jenkins') { steps { sh 'rm -rf ~/app' sh 'docker stop dvna-app && docker stop dvna-mysql' sh 'docker rmi appsecco/dvna' } } stage ('Deploy DVNA to Production') { steps { sh 'ssh -tt -o StrictHostKeyChecking=no prod-vm@192.168.1.55 \"docker stop dvna-app && docker stop dvna-mysql && docker rm dvna-app && docker rm dvna-mysql && docker rmi appsecco/dvna || true\"' sh 'scp ~/vars.env prod-vm@192.168.1.55:~/' sh 'ssh -tt -o StrictHostKeyChecking=no prod-vm@192.168.1.55 \"docker run -d --name dvna-mysql --env-file ~/vars.env mysql:5.7 tail -f /dev/null\"' sh 'ssh -tt -o StrictHostKeyChecking=no prod-vm@192.168.1.55 \"docker run -d --name dvna-app --env-file ~/vars.env --link dvna-mysql:mysql-db -p 9090:9090 appsecco/dvna\"' } } } } pipeline - Constitutes the entire definition of the pipeline. agent - Is used to choose the way the Jenkins instance(s) are used to run the pipeline. The any keyword defines that Jenkins should - allocate any available agent (an instance of Jenkins/a slave/the master instance) to execute the pipeline. stages - Consists of all the stages/jobs to be performed during the execution of the pipeline. stage - Specify the task to be performed. steps - This block defines actions to be performed within a particular stage. sh - Used to execute shell commands through Jenkins.","title":"Jenkinsfile"},{"location":"Working-of-pipeline/#stages","text":"The pipeline is divided into various stages based on the operations being performed, which are as follows:","title":"Stages"},{"location":"Working-of-pipeline/#initialization","text":"This is the first stage which is used to just display the start of the building stage.","title":"Initialization"},{"location":"Working-of-pipeline/#build","text":"This stage contains the environment variables, in which vars.env file is created and for dvna-mysql container. dvna-app and dvna-mysql containers will run and will be copied into the home directory.","title":"Build"},{"location":"Working-of-pipeline/#static-and-dynamic-analysis","text":"All the stages that follow the Build Stage, except for the last two stages, are for performing static analysis and dynamic analysis on DVNA and later being stored in a folder reports in jenkins home directory.","title":"Static and Dynamic Analysis"},{"location":"Working-of-pipeline/#remove-dvna-from-jenkins","text":"After the scans are complete, the containers running in Jenkins VM are stopped and removed. Since we're working with a containerized application (DVNA), we need to perform tests on the latest available image on DockerHub. Hence, we remove the existing local appsecco/dvna docker image to avoid running a container with older release of the application image. On the other hand, you don't need to remove the mysql:5.7 image, since we require v5.7 and not the latest version.","title":"Remove DVNA from Jenkins"},{"location":"Working-of-pipeline/#deployment","text":"Finally, the satge deploy to dvna , operations are performed on VM over SSH which was configured previously. The two containers, dvna-app and dvna-mysql are run and successfully deployed.","title":"Deployment"},{"location":"contents/","text":"Table of contents Introduction Table of contents Problem Statements setting-up-VM setting up jenkins setting up mkdocs setting up pipeline setting up dvna Static Analysis Software Composition Analysis Dynamic Analysis Source Code Quality Analysis Complete Pipeline Resources","title":"Contents"},{"location":"contents/#table-of-contents","text":"Introduction Table of contents Problem Statements setting-up-VM setting up jenkins setting up mkdocs setting up pipeline setting up dvna Static Analysis Software Composition Analysis Dynamic Analysis Source Code Quality Analysis Complete Pipeline Resources","title":"Table of contents"},{"location":"dokcer/","text":"Docker Docker is a software platform that allows you to build, test, and deploy applications quickly. Docker packages software into standardized units called containers that have everything the software needs to run including libraries, system tools, code, and runtime. Using Docker, you can quickly deploy and scale applications into any environment and know your code will run.I refered the official documentation to know more about the docker. Docker provides the ability to package and run an application in a loosely isolated environment called a container. Containers are lightweight and contain everything needed to run the application, so you do not need to rely on what is currently installed on the host. You can easily share containers while you work, and be sure that everyone you share with gets the same container that works in the same way. Install Docke Engine Update the apt package index, and install the latest version od\\f Docker Engine and containerd: sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io ansd then on a production server, run: docker run --name dvna -p 9090:9090 -d appsecco/dvna:sqlite","title":"Docker"},{"location":"dokcer/#docker","text":"Docker is a software platform that allows you to build, test, and deploy applications quickly. Docker packages software into standardized units called containers that have everything the software needs to run including libraries, system tools, code, and runtime. Using Docker, you can quickly deploy and scale applications into any environment and know your code will run.I refered the official documentation to know more about the docker. Docker provides the ability to package and run an application in a loosely isolated environment called a container. Containers are lightweight and contain everything needed to run the application, so you do not need to rely on what is currently installed on the host. You can easily share containers while you work, and be sure that everyone you share with gets the same container that works in the same way.","title":"Docker"},{"location":"dokcer/#install-docke-engine","text":"Update the apt package index, and install the latest version od\\f Docker Engine and containerd: sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io ansd then on a production server, run: docker run --name dvna -p 9090:9090 -d appsecco/dvna:sqlite","title":"Install Docke Engine"},{"location":"setting-up-VM/","text":"What is Virtual Machine? For understanding Virtual machine (VM) we will have to understand what Virtualization is. Virtualization is a software based or virtual version of something, that be compute, storage, networking, servers or applications. And Hypervisor makes Virtualization possible. Hypervisor is a piece of software that runs above host or server. There are 2 types of hypervisors: Type 1: It is installed directly on top of physical server. Type 2: Here there is a layer of Host operating system (OS) between the hardware and Hypervisor (as we are using here). A VM is an OS or application environment that is installed on software, which imitates dedicated physical server. A VM provides an isolated environment for running its own OS and applications independently from the underlying host system or from other VMs on that host. The VM's OS is commonly referred to as the guest OS, and it can be the same as or different from the host OS or the other VMs. Setting up VM Here I will be setting up two VMs: For Jenkins Deployment. For suiteCRM server. In virtual Box Click NEW icon to create a new machine. Name and operating system Name : Jenkins-deploy Type : Linux Version : Ubuntu (64-bit) Memory size Select 2000 MB and click on create . Hard disk Select a virtual hard disk now and Create and Hard disk file type will open in that select VDI (VirtualBox Disk Image) and NEXT . In storage on physical hard disk select Dynamically allocated File location and size will open hit Create and is done. Download server image 18.04 Downloaded the server image Ubuntu 18.04 on VirtualBox as it is an LTS version which is a desirable feature for a CI pipeline. I followed the official link to download the 64-bit PC(AMD64) desktop image In VM box I selected Jenkins-deploy to install the server and then clicked on start . Then the Select start-up disk window opened and I clicked on the folder which gave a new screen Optical Disk Selector. I selected the server image and clicked on Choose after that click on start . Now Jenkin VM starts running! Language selection Select the language English and click on done Keyboard configuration By default, English is selected for Layout and variant, pressed Done . Network connections I kept it as default and selected Done . Configure proxy Configure ubuntu archive mirror I kept it as default and pressed Done for both Configure proxy and configure ubuntu archive mirror Storage configuration I did not make changes in the storage configuration I kept it as default and pressed Done . I kept this too as default and hit Done . Profile setup I provided all the details and pressed Done . SSH Setup In order to install the OpenSSH server I pressed Space button to select the Install OpenSSH server option. I selected the install openSSH server because by default ubuntu did not have openSSH installed, and then I kept Import SSH identity as default and pressed Done . Featured Server Snaps Selected the snaps which are useful in a server environment, once selected pressed Done . Installation complete Installation complete window appeared, I waited until the Reboot button appeared on this window. Later, pressed reboot . And the installation of Ubuntu 18.04 is completed! Repeat the same process in order to create another VM for suiteCRM deployment where I have specified the server name as suitecrm-deploy .","title":"Setting up VM"},{"location":"setting-up-VM/#what-is-virtual-machine","text":"For understanding Virtual machine (VM) we will have to understand what Virtualization is. Virtualization is a software based or virtual version of something, that be compute, storage, networking, servers or applications. And Hypervisor makes Virtualization possible. Hypervisor is a piece of software that runs above host or server. There are 2 types of hypervisors: Type 1: It is installed directly on top of physical server. Type 2: Here there is a layer of Host operating system (OS) between the hardware and Hypervisor (as we are using here). A VM is an OS or application environment that is installed on software, which imitates dedicated physical server. A VM provides an isolated environment for running its own OS and applications independently from the underlying host system or from other VMs on that host. The VM's OS is commonly referred to as the guest OS, and it can be the same as or different from the host OS or the other VMs.","title":"What is Virtual Machine?"},{"location":"setting-up-VM/#setting-up-vm","text":"Here I will be setting up two VMs: For Jenkins Deployment. For suiteCRM server. In virtual Box Click NEW icon to create a new machine.","title":"Setting up VM"},{"location":"setting-up-VM/#name-and-operating-system","text":"Name : Jenkins-deploy Type : Linux Version : Ubuntu (64-bit)","title":"Name and operating system"},{"location":"setting-up-VM/#memory-size","text":"Select 2000 MB and click on create .","title":"Memory size"},{"location":"setting-up-VM/#hard-disk","text":"Select a virtual hard disk now and Create and Hard disk file type will open in that select VDI (VirtualBox Disk Image) and NEXT . In storage on physical hard disk select Dynamically allocated File location and size will open hit Create and is done.","title":"Hard disk"},{"location":"setting-up-VM/#download-server-image-1804","text":"Downloaded the server image Ubuntu 18.04 on VirtualBox as it is an LTS version which is a desirable feature for a CI pipeline. I followed the official link to download the 64-bit PC(AMD64) desktop image In VM box I selected Jenkins-deploy to install the server and then clicked on start . Then the Select start-up disk window opened and I clicked on the folder which gave a new screen Optical Disk Selector. I selected the server image and clicked on Choose after that click on start . Now Jenkin VM starts running!","title":"Download server image 18.04"},{"location":"setting-up-VM/#language-selection","text":"Select the language English and click on done","title":"Language selection"},{"location":"setting-up-VM/#keyboard-configuration","text":"By default, English is selected for Layout and variant, pressed Done .","title":"Keyboard configuration"},{"location":"setting-up-VM/#network-connections","text":"I kept it as default and selected Done .","title":"Network connections"},{"location":"setting-up-VM/#configure-proxy","text":"","title":"Configure proxy"},{"location":"setting-up-VM/#configure-ubuntu-archive-mirror","text":"I kept it as default and pressed Done for both Configure proxy and configure ubuntu archive mirror","title":"Configure ubuntu archive mirror"},{"location":"setting-up-VM/#storage-configuration","text":"I did not make changes in the storage configuration I kept it as default and pressed Done . I kept this too as default and hit Done .","title":"Storage configuration"},{"location":"setting-up-VM/#profile-setup","text":"I provided all the details and pressed Done .","title":"Profile setup"},{"location":"setting-up-VM/#ssh-setup","text":"In order to install the OpenSSH server I pressed Space button to select the Install OpenSSH server option. I selected the install openSSH server because by default ubuntu did not have openSSH installed, and then I kept Import SSH identity as default and pressed Done .","title":"SSH Setup"},{"location":"setting-up-VM/#featured-server-snaps","text":"Selected the snaps which are useful in a server environment, once selected pressed Done .","title":"Featured Server Snaps"},{"location":"setting-up-VM/#installation-complete","text":"Installation complete window appeared, I waited until the Reboot button appeared on this window. Later, pressed reboot . And the installation of Ubuntu 18.04 is completed! Repeat the same process in order to create another VM for suiteCRM deployment where I have specified the server name as suitecrm-deploy .","title":"Installation complete"},{"location":"setting-up-dvna/","text":"Configuring Production VM The aim of this section is to setup the production server for deploying DVNA. Damn Vulnerable NodeJS Application (DVNA) is a simple NodeJS application to demonstrate OWASP Top 10 Vulnerabilities and guide on fixing and avoiding these vulnerabilities Requirements To serve DVNA, there are some prerequisites: - VM running Ubuntu 18.04 LTS. - Docker, NodeJS and NPM Install Docker, NodeJS and NPM For Docker installation I referred the official documentation , update the apt package index: sudo apt-get update Add Docker\u2019s official GPG key: curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg Use the following command to set up the stable repository: echo \\ \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null Update the apt package index, and install the latest version of Docker Engine and containerd, or go to the next step to install a specific version: sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io sudo docker run hello-world # Test if docker installation is successful Install NodeJS and NPM: sudo curl -sL https://deb.nodesource.com/setup_14.x | sudo -E bash - && sudo apt install -y nodejs Setup DVNA I followed the official documentation for setup. Create a file named vars.env with the following configuration: MYSQL_USER=dvna MYSQL_DATABASE=dvna MYSQL_PASSWORD=passw0rd MYSQL_RANDOM_ROOT_PASSWORD=yes MYSQL_HOST=mysql-db MYSQL_PORT=3306 Start a MySQL container, unless you want to use your own, in which case configure in the env file above. docker run --name dvna-mysql --env-file vars.env -d mysql:5.7 Start the application using the official image: docker run --name dvna-app --env-file vars.env --link dvna-mysql:mysql-db -p 9090:9090 appsecco/dvna To test if the containers are running, run docker ps -a you will see two containers running dvna-app and dvna-mysql and docker stop for stopping the container. Access the application at http://your-ip-address:8080.","title":"Setting up DVNA"},{"location":"setting-up-dvna/#configuring-production-vm","text":"The aim of this section is to setup the production server for deploying DVNA. Damn Vulnerable NodeJS Application (DVNA) is a simple NodeJS application to demonstrate OWASP Top 10 Vulnerabilities and guide on fixing and avoiding these vulnerabilities","title":"Configuring Production VM"},{"location":"setting-up-dvna/#requirements","text":"To serve DVNA, there are some prerequisites: - VM running Ubuntu 18.04 LTS. - Docker, NodeJS and NPM","title":"Requirements"},{"location":"setting-up-dvna/#install-docker-nodejs-and-npm","text":"For Docker installation I referred the official documentation , update the apt package index: sudo apt-get update Add Docker\u2019s official GPG key: curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg Use the following command to set up the stable repository: echo \\ \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null Update the apt package index, and install the latest version of Docker Engine and containerd, or go to the next step to install a specific version: sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io sudo docker run hello-world # Test if docker installation is successful Install NodeJS and NPM: sudo curl -sL https://deb.nodesource.com/setup_14.x | sudo -E bash - && sudo apt install -y nodejs","title":"Install Docker, NodeJS and NPM"},{"location":"setting-up-dvna/#setup-dvna","text":"I followed the official documentation for setup. Create a file named vars.env with the following configuration: MYSQL_USER=dvna MYSQL_DATABASE=dvna MYSQL_PASSWORD=passw0rd MYSQL_RANDOM_ROOT_PASSWORD=yes MYSQL_HOST=mysql-db MYSQL_PORT=3306 Start a MySQL container, unless you want to use your own, in which case configure in the env file above. docker run --name dvna-mysql --env-file vars.env -d mysql:5.7 Start the application using the official image: docker run --name dvna-app --env-file vars.env --link dvna-mysql:mysql-db -p 9090:9090 appsecco/dvna To test if the containers are running, run docker ps -a you will see two containers running dvna-app and dvna-mysql and docker stop for stopping the container. Access the application at http://your-ip-address:8080.","title":"Setup DVNA"},{"location":"setting-up-jenkins/","text":"Installation of Jenkins What is Jenkins? Jenkins is a self-contained, open-source automation server which can be used to automate all sorts of tasks related to building, testing, and delivering or deploying software. Prerequisite I have setup ubuntu 18.04 VM for installing Jenkins from Documentation . I have installed java 8 OpenJDK and JRE (Java Development Kit and Java Runtime Environment) which is used to develop and run the software, I have used this Link to download the same. Installation steps for Jenkins Add the repository key to the terminal: wget -q -O - https://pkg.jenkins.io/debian-stable/jenkins.io.key | sudo apt-key add - The system will return OK Next, add the Debian package repository address: sudo sh -c 'echo deb https://pkg.jenkins.io/debian-stable binary/ > \\ /etc/apt/sources.list.d/jenkins.list sudo apt update Now install Jenkins and it\u2019s dependencies: sudo apt install jenkins Starting Jenkins The systemctl command is used to manage \"systemd\" services and service manager: sudo systemctl start jenkins Check the status of Jenkins service using the below command: sudo systemctl status jenkins If the Jenkins has installed successfully, then the output will show as Active: active(excited) . To reach it from a web browser I will adjust the firewall rules to complete the initial setup. Set-up a Firewall with UFW Firewall is a software controlling incoming and outgoing network traffic. Firewall is able to manage traffic by monitoring network ports. By default, Jenkins runs on port 8080. Opening using ufw(uncomplicated firewall): sudo ufw allow 8080 To check the status of the ufw: sudo ufw status If the status shows \"Inactive\". Then enable using following command To configure your server to allow incoming SSH connections, you can use this command: sudo ufw allow ssh To enable UFW, use this command: sudo ufw enable Setting up Jenkins To find your server's name or domain name enter the following command in your terminal: ifconfig Using the server's name or domain name as shown in the following command, entered that into a browser which in turn gave the Unlock Jenkins window. http://your_server_name_or_domain:8080 Using that server name The Unlock Jenkins window shows where the admin password is stored. In the terminal I will use the cat command to display the password: sudo cat /var/lib/jenkins/secrets/initialAdminPassword The 32-character alphanumeric password is displayed in the terminal, paste it onto Administrator password field, and then click continue . Customize Jenkins In the Customize Jenkins select \"install suggested plugins\" which will start installation process directly and press continue . Create Admin User Add the required credentials, click on save and continue as admin. The \"Instance configuration\" page will be displayed which will ask to confirm the preferred URL for Jenkins instance, click on save and finish . Installation Starts Once the process is over click on Reboot which will restart the Jenkins. Now, Jenkins is installed!","title":"Setting up Jenkins"},{"location":"setting-up-jenkins/#installation-of-jenkins","text":"","title":"Installation of Jenkins"},{"location":"setting-up-jenkins/#what-is-jenkins","text":"Jenkins is a self-contained, open-source automation server which can be used to automate all sorts of tasks related to building, testing, and delivering or deploying software.","title":"What is Jenkins?"},{"location":"setting-up-jenkins/#prerequisite","text":"I have setup ubuntu 18.04 VM for installing Jenkins from Documentation . I have installed java 8 OpenJDK and JRE (Java Development Kit and Java Runtime Environment) which is used to develop and run the software, I have used this Link to download the same.","title":"Prerequisite"},{"location":"setting-up-jenkins/#installation-steps-for-jenkins","text":"Add the repository key to the terminal: wget -q -O - https://pkg.jenkins.io/debian-stable/jenkins.io.key | sudo apt-key add - The system will return OK Next, add the Debian package repository address: sudo sh -c 'echo deb https://pkg.jenkins.io/debian-stable binary/ > \\ /etc/apt/sources.list.d/jenkins.list sudo apt update Now install Jenkins and it\u2019s dependencies: sudo apt install jenkins","title":"Installation steps for Jenkins"},{"location":"setting-up-jenkins/#starting-jenkins","text":"The systemctl command is used to manage \"systemd\" services and service manager: sudo systemctl start jenkins Check the status of Jenkins service using the below command: sudo systemctl status jenkins If the Jenkins has installed successfully, then the output will show as Active: active(excited) . To reach it from a web browser I will adjust the firewall rules to complete the initial setup.","title":"Starting Jenkins"},{"location":"setting-up-jenkins/#set-up-a-firewall-with-ufw","text":"Firewall is a software controlling incoming and outgoing network traffic. Firewall is able to manage traffic by monitoring network ports. By default, Jenkins runs on port 8080. Opening using ufw(uncomplicated firewall): sudo ufw allow 8080 To check the status of the ufw: sudo ufw status If the status shows \"Inactive\". Then enable using following command To configure your server to allow incoming SSH connections, you can use this command: sudo ufw allow ssh To enable UFW, use this command: sudo ufw enable","title":"Set-up a Firewall with UFW"},{"location":"setting-up-jenkins/#setting-up-jenkins","text":"To find your server's name or domain name enter the following command in your terminal: ifconfig Using the server's name or domain name as shown in the following command, entered that into a browser which in turn gave the Unlock Jenkins window. http://your_server_name_or_domain:8080","title":"Setting up Jenkins"},{"location":"setting-up-jenkins/#using-that-server-name","text":"The Unlock Jenkins window shows where the admin password is stored. In the terminal I will use the cat command to display the password: sudo cat /var/lib/jenkins/secrets/initialAdminPassword The 32-character alphanumeric password is displayed in the terminal, paste it onto Administrator password field, and then click continue .","title":"Using that server name"},{"location":"setting-up-jenkins/#customize-jenkins","text":"In the Customize Jenkins select \"install suggested plugins\" which will start installation process directly and press continue .","title":"Customize Jenkins"},{"location":"setting-up-jenkins/#create-admin-user","text":"Add the required credentials, click on save and continue as admin. The \"Instance configuration\" page will be displayed which will ask to confirm the preferred URL for Jenkins instance, click on save and finish .","title":"Create Admin User"},{"location":"setting-up-jenkins/#installation-starts","text":"Once the process is over click on Reboot which will restart the Jenkins. Now, Jenkins is installed!","title":"Installation Starts"},{"location":"setting-up-maven-pipeline/","text":"Jenkins Pipeline Why use Jenkins pipeline ? Jenkins is an open continuous integration server which has the ability to support the automation of software development processes. You can create multiple automation jobs with the help of use cases, and run them as a Jenkins pipeline. Here are the reasons why you use should use Jenkins pipeline: Jenkins pipeline is implemented as a code which allows multiple users to edit and execute the pipeline process. Pipelines are robust. So, if your server undergoes an unforeseen restart, the pipeline will be automatically resumed. You can pause the pipeline process and make it wait to resume until there is an input from the user. Jenkins Pipelines support big projects. You can run multiple jobs, and even use pipelines in a loop. Setup Jenkins Pipeline Here, we are using Apache Maven as a plugin which is a software project management and comprehension tool. Based on the concept of a project object model (POM), Maven can manage a project's build, reporting and documentation from a central piece of information. Jenkins provides a particular job type, which explicitly provides options for configuring and executing a Maven project. This job type is called the Maven project Let\u2019s see how we can create a Maven project in Jenkins and run the same. Install Maven Plugin in Jenkins Click on the Manage Jenkins as shown below. Under the System Configuration section, click on the Manage Plugins options. Under the Plugin Manager, click on the Available tab and search for the maven plugin. It will show the Maven Integration plugin as a result and check the checkbox and select install without restart . Once the plugin installs successfully, click the checkbox to restart Jenkins. After the restart of Jenkins, the Maven Jenkins plugin will be installed successfully and ready for configuration. Create A Maven project in Jenkins. Firstly, we need to create a job. To create this, click on New Item option. Now, enter item name as Jenkin-Maven and selct Maven project as shown below and click on OK . Here, under general section: I gave the description of the project. Under Source Code Management I checked the Git option and provided the Github URl . This helps jenkins to know where to fetch the project from. Under Build Triggers : I checked Build whenever a SNAPSHOT dependency is built this is convenient for automatically performing continuous integration. Jenkins will check the snapshot dependencies from the dependency element in the POM, as well as plugins and extensions used in POMs. Later, clicked on save button. What is Jenkinsfile? Jenkins Pipeline has a customizable and scalable automation system that lets you build distribution pipeline scripts - \u201cPipeline as Code\u201d, these scripts are called JenkinsFile. A JenkinsFile stores the entire CI/CD process as code on the local machine. As such, the file can be reviewed and checked into a Source Code Management (SCM) platform (be it Git or SVN) along with your code. Hence, the term \u201cPipeline as Code\u201d. The structure of my jenkinsfile is as follows: pipeline { agent any stages { stage ('Compile Stage') { steps { withMaven(maven : 'maven_3_6_0') { sh 'mvn clean compile' } } } stage ('Testing Stage') { steps { withMaven(maven : 'maven_3_6_0') { sh 'mvn test' } } } stage ('Deployment Stage') { steps { withMaven(maven : 'maven_3_6_0') { sh 'mvn deploy' } } } } } SSH Access Configuration Secure Shell Protocol (SSH) provides a secure channel over an unsecured network by using a client\u2013server architecture, connecting an SSH client application with an SSH server. The standard TCP port for SSH is 22. Installation In order to SSH into VM we need to install it! sudo apt-get install openssh-server Enable the ssh service by: sudo systemctl enable ssh Start the ssh service: sudo systemctl start ssh SSH into VM Goto VM - Settings > Network > Advanced > Port Forwarding After installing SSH, create a key pair on a client machine. ssh-keygen -t ed25519 The first prompt from the ssh-keygen command will ask you where to save the keys, I pressed enter to save as it was. Similarly, Creating passphrase just pressed enter . once the key is generated, place the public key on the server which you want to connect to. Following the command below: ssh-copy-id username@your_server_address While copying the id I got an error \"cannot create .ssh/ authorized keys permission denied\", so I changed the permissions of the authorized_keys file and the folder/parent folders in which it is located. chmod 700 ~/.ssh chmod 600 ~/.ssh/authorized_keys - Also, I changed the permissions of home directory to remove write access for the group and others. chmod go-w ~ Provide the information as shown above. ssh username@server_ip_address I got an error saying permission denied, I refered this documentation and did the necessary changes which are: Type the below command in your termianl: sudo nano /etc/ssh/sshd_config And change permissions as given below: PermitRootLogin yes PasswordAuthentication yes And don't forget to reload: sudo systemctl restart ssh.service After installing SSH, create a key pair on a client machine. ssh-keygen -t rsa - The first prompt from the ssh-keygen command will ask you where to save the keys, I pressed enter to save as it was. - Similarly, Creating passphrase just pressed enter . - once the key is generated, place the public key on the server which you want to connect to. Following the command below: ssh-copy-id username@your_server_address Setup SSH keys for Jenkins You will need to create a public/private key as the Jenkins user on your Jenkins server, then copy the public key to the user you want to do the deployment with on your target server. Generate public and private key on build server as user jenkins and paste the pub file contents onto the target server. Make sure your .ssh dir has permissoins 700 and your authorized_keys file has permissions 644. In the jenkins web control panel, install the plugin [Publish Over SSH](https://plugins.jenkins.io/publish-over-ssh/ and nagivate to \"Manage Jenkins\" -> \"Configure System\" -> \"Publish over SSH\". Either enter the path of the file e.g. \"var/lib/jenkins/.ssh/id_rsa\", or paste in the same content as on the target server. Enter your passphrase, server and user details, and you are good to go!","title":"Jenkins Pipeline"},{"location":"setting-up-maven-pipeline/#jenkins-pipeline","text":"","title":"Jenkins Pipeline"},{"location":"setting-up-maven-pipeline/#why-use-jenkins-pipeline","text":"Jenkins is an open continuous integration server which has the ability to support the automation of software development processes. You can create multiple automation jobs with the help of use cases, and run them as a Jenkins pipeline. Here are the reasons why you use should use Jenkins pipeline: Jenkins pipeline is implemented as a code which allows multiple users to edit and execute the pipeline process. Pipelines are robust. So, if your server undergoes an unforeseen restart, the pipeline will be automatically resumed. You can pause the pipeline process and make it wait to resume until there is an input from the user. Jenkins Pipelines support big projects. You can run multiple jobs, and even use pipelines in a loop.","title":"Why use Jenkins pipeline ?"},{"location":"setting-up-maven-pipeline/#setup-jenkins-pipeline","text":"Here, we are using Apache Maven as a plugin which is a software project management and comprehension tool. Based on the concept of a project object model (POM), Maven can manage a project's build, reporting and documentation from a central piece of information. Jenkins provides a particular job type, which explicitly provides options for configuring and executing a Maven project. This job type is called the Maven project Let\u2019s see how we can create a Maven project in Jenkins and run the same.","title":"Setup Jenkins Pipeline"},{"location":"setting-up-maven-pipeline/#install-maven-plugin-in-jenkins","text":"Click on the Manage Jenkins as shown below. Under the System Configuration section, click on the Manage Plugins options. Under the Plugin Manager, click on the Available tab and search for the maven plugin. It will show the Maven Integration plugin as a result and check the checkbox and select install without restart . Once the plugin installs successfully, click the checkbox to restart Jenkins. After the restart of Jenkins, the Maven Jenkins plugin will be installed successfully and ready for configuration.","title":"Install Maven Plugin in Jenkins"},{"location":"setting-up-maven-pipeline/#create-a-maven-project-in-jenkins","text":"Firstly, we need to create a job. To create this, click on New Item option. Now, enter item name as Jenkin-Maven and selct Maven project as shown below and click on OK . Here, under general section: I gave the description of the project. Under Source Code Management I checked the Git option and provided the Github URl . This helps jenkins to know where to fetch the project from. Under Build Triggers : I checked Build whenever a SNAPSHOT dependency is built this is convenient for automatically performing continuous integration. Jenkins will check the snapshot dependencies from the dependency element in the POM, as well as plugins and extensions used in POMs. Later, clicked on save button.","title":"Create A Maven project in Jenkins."},{"location":"setting-up-maven-pipeline/#what-is-jenkinsfile","text":"Jenkins Pipeline has a customizable and scalable automation system that lets you build distribution pipeline scripts - \u201cPipeline as Code\u201d, these scripts are called JenkinsFile. A JenkinsFile stores the entire CI/CD process as code on the local machine. As such, the file can be reviewed and checked into a Source Code Management (SCM) platform (be it Git or SVN) along with your code. Hence, the term \u201cPipeline as Code\u201d. The structure of my jenkinsfile is as follows: pipeline { agent any stages { stage ('Compile Stage') { steps { withMaven(maven : 'maven_3_6_0') { sh 'mvn clean compile' } } } stage ('Testing Stage') { steps { withMaven(maven : 'maven_3_6_0') { sh 'mvn test' } } } stage ('Deployment Stage') { steps { withMaven(maven : 'maven_3_6_0') { sh 'mvn deploy' } } } } }","title":"What is Jenkinsfile?"},{"location":"setting-up-maven-pipeline/#ssh-access-configuration","text":"Secure Shell Protocol (SSH) provides a secure channel over an unsecured network by using a client\u2013server architecture, connecting an SSH client application with an SSH server. The standard TCP port for SSH is 22.","title":"SSH Access Configuration"},{"location":"setting-up-maven-pipeline/#installation","text":"In order to SSH into VM we need to install it! sudo apt-get install openssh-server Enable the ssh service by: sudo systemctl enable ssh Start the ssh service: sudo systemctl start ssh","title":"Installation"},{"location":"setting-up-maven-pipeline/#ssh-into-vm","text":"Goto VM - Settings > Network > Advanced > Port Forwarding After installing SSH, create a key pair on a client machine. ssh-keygen -t ed25519 The first prompt from the ssh-keygen command will ask you where to save the keys, I pressed enter to save as it was. Similarly, Creating passphrase just pressed enter . once the key is generated, place the public key on the server which you want to connect to. Following the command below: ssh-copy-id username@your_server_address While copying the id I got an error \"cannot create .ssh/ authorized keys permission denied\", so I changed the permissions of the authorized_keys file and the folder/parent folders in which it is located. chmod 700 ~/.ssh chmod 600 ~/.ssh/authorized_keys","title":"SSH into VM"},{"location":"setting-up-maven-pipeline/#-also-i-changed-the-permissions-of-home-directory-to-remove-write-access-for-the-group-and-others","text":"chmod go-w ~ Provide the information as shown above. ssh username@server_ip_address I got an error saying permission denied, I refered this documentation and did the necessary changes which are: Type the below command in your termianl: sudo nano /etc/ssh/sshd_config And change permissions as given below: PermitRootLogin yes PasswordAuthentication yes And don't forget to reload: sudo systemctl restart ssh.service After installing SSH, create a key pair on a client machine. ssh-keygen -t rsa - The first prompt from the ssh-keygen command will ask you where to save the keys, I pressed enter to save as it was. - Similarly, Creating passphrase just pressed enter . - once the key is generated, place the public key on the server which you want to connect to. Following the command below: ssh-copy-id username@your_server_address","title":"- Also, I changed the permissions of home directory to remove write access for the group and others."},{"location":"setting-up-maven-pipeline/#setup-ssh-keys-for-jenkins","text":"You will need to create a public/private key as the Jenkins user on your Jenkins server, then copy the public key to the user you want to do the deployment with on your target server. Generate public and private key on build server as user jenkins and paste the pub file contents onto the target server. Make sure your .ssh dir has permissoins 700 and your authorized_keys file has permissions 644. In the jenkins web control panel, install the plugin [Publish Over SSH](https://plugins.jenkins.io/publish-over-ssh/ and nagivate to \"Manage Jenkins\" -> \"Configure System\" -> \"Publish over SSH\". Either enter the path of the file e.g. \"var/lib/jenkins/.ssh/id_rsa\", or paste in the same content as on the target server. Enter your passphrase, server and user details, and you are good to go!","title":"Setup SSH keys for Jenkins"},{"location":"setting-up-mkdocs/","text":"Setting up MKDocs MkDocs is a static site generator that's geared towards building project documentation. Documentation source files are written in Markdown, and configured with a single YAML configuration file. MkDocs will build your docs and used to commit and push them to GitHub. Installing MKDocs I have installed MKDocs using the official Documentation If you need to install pip for the first time, download get-pip.py . Then run the following command to install it: python get-pip.py Install the MKDocs package using: pip insatll mkdocs Later, check the version of the MKDocs installed in order to check everything worked okay. mkdocs --version Selecting a Theme In order to customize a theme, I referred official Documentation from MkDocs themes. Here I preferred Material theme, to use this particular theme it needs to be installed via pip. pip install mkdocs-material Configuration Create a new project to store all the documentation as given in below commands: mkdocs new my-project cd my-project After creating a folder in VScode, create a file named mkdocs.yml and a folder named docs . The index.md file is created in docs folder which contains a single documentation page. In mkdocs.yml include: site_name: 'DevSecOps-pipeline' nav: Introduction: 'index.md' Contents: 'contents.md' Setting up VM: 'setting-up-VM.md' Setting up Jenkins: 'setting-up-jenkins.md' Setting up mkDocs: 'setting-up-mkdocs.md' theme: material Here we have mentioned the site name as DevSecOps-pipeline which is the title of the site, in the nav include all the contents which are explained throughout the documentation and the theme as we have downloaded before needs to be mentioned here. Push code to GitHub Here, I made a repository initially as DevSecOps-Internship also checked the option private repository and then create repository . In a terminal, I ran: git init mkdocs build git add . git commit -m \"Initial commit\" git push -u origin master Later, I checked the repository all the files where not committed. I figured this out by checking the contents.md file, where I forgot to add the files that were created. I again committed the files using the commands as above, now the files were successfully committed. Building the MKDocs site Building a site converts the documented files into a HTML and CSS format and will the files in a folder named site within the same directory which contains mkdocs.yml file. In the terminal I ran a following command from parent directory: mkdocs build --clean Deploy on Netlify Created a account in netlify . Selected Add a new project option. A window will open which asks for Connect to git provider . Select Create a new site and later select Github . Select the repository you need to publish, I selected DevSecOps-pipeline. later select the repository and a window will appear under that add site/ in publish directory. Click on Deploy site and the site will be deployed and the link will be available on top of the screen.","title":"Setting up mkDocs"},{"location":"setting-up-mkdocs/#setting-up-mkdocs","text":"MkDocs is a static site generator that's geared towards building project documentation. Documentation source files are written in Markdown, and configured with a single YAML configuration file. MkDocs will build your docs and used to commit and push them to GitHub.","title":"Setting up MKDocs"},{"location":"setting-up-mkdocs/#installing-mkdocs","text":"I have installed MKDocs using the official Documentation If you need to install pip for the first time, download get-pip.py . Then run the following command to install it: python get-pip.py Install the MKDocs package using: pip insatll mkdocs Later, check the version of the MKDocs installed in order to check everything worked okay. mkdocs --version","title":"Installing MKDocs"},{"location":"setting-up-mkdocs/#selecting-a-theme","text":"In order to customize a theme, I referred official Documentation from MkDocs themes. Here I preferred Material theme, to use this particular theme it needs to be installed via pip. pip install mkdocs-material","title":"Selecting a Theme"},{"location":"setting-up-mkdocs/#configuration","text":"Create a new project to store all the documentation as given in below commands: mkdocs new my-project cd my-project After creating a folder in VScode, create a file named mkdocs.yml and a folder named docs . The index.md file is created in docs folder which contains a single documentation page. In mkdocs.yml include: site_name: 'DevSecOps-pipeline' nav: Introduction: 'index.md' Contents: 'contents.md' Setting up VM: 'setting-up-VM.md' Setting up Jenkins: 'setting-up-jenkins.md' Setting up mkDocs: 'setting-up-mkdocs.md' theme: material Here we have mentioned the site name as DevSecOps-pipeline which is the title of the site, in the nav include all the contents which are explained throughout the documentation and the theme as we have downloaded before needs to be mentioned here.","title":"Configuration"},{"location":"setting-up-mkdocs/#push-code-to-github","text":"Here, I made a repository initially as DevSecOps-Internship also checked the option private repository and then create repository . In a terminal, I ran: git init mkdocs build git add . git commit -m \"Initial commit\" git push -u origin master Later, I checked the repository all the files where not committed. I figured this out by checking the contents.md file, where I forgot to add the files that were created. I again committed the files using the commands as above, now the files were successfully committed.","title":"Push code to GitHub"},{"location":"setting-up-mkdocs/#building-the-mkdocs-site","text":"Building a site converts the documented files into a HTML and CSS format and will the files in a folder named site within the same directory which contains mkdocs.yml file. In the terminal I ran a following command from parent directory: mkdocs build --clean","title":"Building the MKDocs site"},{"location":"setting-up-mkdocs/#deploy-on-netlify","text":"Created a account in netlify . Selected Add a new project option. A window will open which asks for Connect to git provider . Select Create a new site and later select Github . Select the repository you need to publish, I selected DevSecOps-pipeline. later select the repository and a window will appear under that add site/ in publish directory. Click on Deploy site and the site will be deployed and the link will be available on top of the screen.","title":"Deploy on Netlify"}]}