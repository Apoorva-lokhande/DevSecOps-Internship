{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Project Title : Managing a DevSecOps Pipeline with Secure Development and Operations Author : Apoorva Lokhande Mentors : Akash Mahajan , Sunesh Govindaraj , Ayush Priya , Priyam Singh This report documents the tasks that I performed as a DevSecOps Engineer at Appsecco . This documentation comprises of my solutions to various tasks alongside different notes on issues I confronted and their correction measures.","title":"Introduction"},{"location":"Complete-pipeline/","text":"Final Pipeline Structure Objective The aim of this section is to perform dynamic analysis using DAST tools on DVNA and solve the 6th point of the Problem Statement . Complete Pipeline Various stages of DVNA (SAST, DAST, Code Quality Analysis, SBoM, SCA) were tested individually, here we have combined all all the segments together. The following is the complete pipeline to perform multiple scans and then deploy it in production: pipeline { agent any stages { stage ('Initialization') { steps { sh 'echo \"Starting the build!\"' } } stage ('Build') { environment { MYSQL_USER=\"dvna\" MYSQL_DATABASE=\"dvna\" MYSQL_PASSWORD=<password> MYSQL_RANDOM_ROOT_PASSWORD=\"yes\" MYSQL_HOST=\"mysql-db\" MYSQL_PORT=3306 } steps { sh 'echo \"MYSQL_USER=$MYSQL_USER\\nMYSQL_DATABASE=$MYSQL_DATABASE\\nMYSQL_PASSWORD=$MYSQL_PASSWORD\\nMYSQL_RANDOM_ROOT_PASSWORD=$MYSQL_RANDOM_ROOT_PASSWORD\\nMYSQL_HOST=$MYSQL_HOST\\nMYSQL_PORT=$MYSQL_PORT\" > ~/vars.env' sh 'docker run --rm -d --name dvna-mysql --env-file ~/vars.env mysql:5.7 tail -f /dev/null' sh 'docker run --rm -d --name dvna-app --env-file ~/vars.env --link dvna-mysql:mysql-db -p 8080:8080 appsecco/dvna' sh 'docker cp dvna-app:/app/ ~/' } } stage('NodeJsScan Analysis') { steps { sh 'njsscan --json -o ~/reports/nodejsscan-report ~/app || true' } } stage('Auditjs Analysis') { steps { sh 'cd ~/app; auditjs ossi > ~/reports/auditjs-report || true' } } stage ('OWASP Dependency-Check Analysis') { steps { sh '~/dependency-check/bin/dependency-check.sh --scan ~/app --out ~/reports/dependency-check-report --format JSON --prettyPrint || true' } } stage('OWASP ZAP Analysis') { steps { sh 'docker run --rm -i -u zap --name owasp-zap -v ~/reports/:/zap/wrk/ owasp/zap2docker-stable zap-baseline.py -t http://192.168.1.55:8080 -r zap-report.html -l PASS || true' } } stage ('Generating Software Bill of Materials') { steps { sh 'cd ~/app && cyclonedx-bom -o ~/reports/sbom.xml' } } stage ('JSHint Analysis') { steps { sh 'jshint $(find ~/app -type f -name \"*.js\" -o -name \"*.ejs\" | grep -v node_modules) > ~/reports/jshint-report || true' } } stage ('ESLint Analysis') { steps { sh 'eslint -c ~/.eslintrc.json -f html --ext .js,.ejs -o ~/reports/eslint-report.html ~/app || true' } } stage ('Remove DVNA from Jenkins') { steps { sh 'rm -rf ~/app' sh 'docker stop dvna-app && docker stop dvna-mysql' sh 'docker rmi appsecco/dvna' } } stage ('Deploy DVNA to Production') { steps { sh 'ssh -tt -o StrictHostKeyChecking=no prod-vm@192.168.1.55 \"docker stop dvna-app && docker stop dvna-mysql && docker rm dvna-app && docker rm dvna-mysql && docker rmi appsecco/dvna || true\"' sh 'scp ~/vars.env prod-vm@192.168.1.55:~/' sh 'ssh -tt -o StrictHostKeyChecking=no prod-vm@192.168.1.55 \"docker run -d --name dvna-mysql --env-file ~/vars.env mysql:5.7 tail -f /dev/null\"' sh 'ssh -tt -o StrictHostKeyChecking=no prod-vm@192.168.1.55 \"docker run -d --name dvna-app --env-file ~/vars.env --link dvna-mysql:mysql-db -p 8080:8080 appsecco/dvna\"' } } } }","title":"Complete Pipeline  Structure"},{"location":"Complete-pipeline/#final-pipeline-structure","text":"Objective The aim of this section is to perform dynamic analysis using DAST tools on DVNA and solve the 6th point of the Problem Statement .","title":"Final Pipeline Structure"},{"location":"Complete-pipeline/#complete-pipeline","text":"Various stages of DVNA (SAST, DAST, Code Quality Analysis, SBoM, SCA) were tested individually, here we have combined all all the segments together. The following is the complete pipeline to perform multiple scans and then deploy it in production: pipeline { agent any stages { stage ('Initialization') { steps { sh 'echo \"Starting the build!\"' } } stage ('Build') { environment { MYSQL_USER=\"dvna\" MYSQL_DATABASE=\"dvna\" MYSQL_PASSWORD=<password> MYSQL_RANDOM_ROOT_PASSWORD=\"yes\" MYSQL_HOST=\"mysql-db\" MYSQL_PORT=3306 } steps { sh 'echo \"MYSQL_USER=$MYSQL_USER\\nMYSQL_DATABASE=$MYSQL_DATABASE\\nMYSQL_PASSWORD=$MYSQL_PASSWORD\\nMYSQL_RANDOM_ROOT_PASSWORD=$MYSQL_RANDOM_ROOT_PASSWORD\\nMYSQL_HOST=$MYSQL_HOST\\nMYSQL_PORT=$MYSQL_PORT\" > ~/vars.env' sh 'docker run --rm -d --name dvna-mysql --env-file ~/vars.env mysql:5.7 tail -f /dev/null' sh 'docker run --rm -d --name dvna-app --env-file ~/vars.env --link dvna-mysql:mysql-db -p 8080:8080 appsecco/dvna' sh 'docker cp dvna-app:/app/ ~/' } } stage('NodeJsScan Analysis') { steps { sh 'njsscan --json -o ~/reports/nodejsscan-report ~/app || true' } } stage('Auditjs Analysis') { steps { sh 'cd ~/app; auditjs ossi > ~/reports/auditjs-report || true' } } stage ('OWASP Dependency-Check Analysis') { steps { sh '~/dependency-check/bin/dependency-check.sh --scan ~/app --out ~/reports/dependency-check-report --format JSON --prettyPrint || true' } } stage('OWASP ZAP Analysis') { steps { sh 'docker run --rm -i -u zap --name owasp-zap -v ~/reports/:/zap/wrk/ owasp/zap2docker-stable zap-baseline.py -t http://192.168.1.55:8080 -r zap-report.html -l PASS || true' } } stage ('Generating Software Bill of Materials') { steps { sh 'cd ~/app && cyclonedx-bom -o ~/reports/sbom.xml' } } stage ('JSHint Analysis') { steps { sh 'jshint $(find ~/app -type f -name \"*.js\" -o -name \"*.ejs\" | grep -v node_modules) > ~/reports/jshint-report || true' } } stage ('ESLint Analysis') { steps { sh 'eslint -c ~/.eslintrc.json -f html --ext .js,.ejs -o ~/reports/eslint-report.html ~/app || true' } } stage ('Remove DVNA from Jenkins') { steps { sh 'rm -rf ~/app' sh 'docker stop dvna-app && docker stop dvna-mysql' sh 'docker rmi appsecco/dvna' } } stage ('Deploy DVNA to Production') { steps { sh 'ssh -tt -o StrictHostKeyChecking=no prod-vm@192.168.1.55 \"docker stop dvna-app && docker stop dvna-mysql && docker rm dvna-app && docker rm dvna-mysql && docker rmi appsecco/dvna || true\"' sh 'scp ~/vars.env prod-vm@192.168.1.55:~/' sh 'ssh -tt -o StrictHostKeyChecking=no prod-vm@192.168.1.55 \"docker run -d --name dvna-mysql --env-file ~/vars.env mysql:5.7 tail -f /dev/null\"' sh 'ssh -tt -o StrictHostKeyChecking=no prod-vm@192.168.1.55 \"docker run -d --name dvna-app --env-file ~/vars.env --link dvna-mysql:mysql-db -p 8080:8080 appsecco/dvna\"' } } } }","title":"Complete Pipeline"},{"location":"DAST/","text":"Dynamic Analysis Objective The aim of this section is to perform dynamic analysis using DAST tools on DVNA and solve the 6th point of the Problem Statement . What is DAST Dynamic application security testing (DAST) is the process of testing and evaluating a program while software is running. Also referred to as dynamic code scanning, dynamic analysis improves the diagnosis and correction of bugs, memory issues, and crashes of an application during its execution. Why is Dynamic Analysis Needed? DAST is a method of AppSec testing that examines an application while it\u2019s running, without knowledge of the application\u2019s internal interactions or designs at the system level, and with no access or visibility into the source program. This \u201cblack box\u201d testing looks at an application from the outside in, examines its running state, and observes its responses to simulated attacks made by the tool. An application\u2019s responses to these simulations help determine whether the application is vulnerable and could be susceptible to a real malicious attack. Static Vs Dynamic Analysis Static code analysis is done by examining the code without the need to execute the program. The process provides an understanding of the code structure and can help ensure that the code adheres to industry standards. All code is scanned to check for any vulnerabilities and ensure the code is validated. Dynamic analysis adopts the opposite approach and is executed while a program is in operation. Dynamic analysis performs continuous and concurrent risk assessments, searching for vulnerabilities within web applications and speeding interventions. OWASP ZAP ZAP is an open source tool which is offered by OWASP (Open Web Application Security Project), for penetration testing of your website/web application. It helps you find the security vulnerabilities in your application. ZAP creates a proxy server and makes your website traffic pass through that server. It comprises of auto scanners that help you intercept the vulnerabilities in your website. I followed the official documentation and pulled the ZAP image from docker: docker pull owasp/zap2docker-stable I got an permission denied error, and resolved it by changing the permissions as below: sudo chmod 666 /var/run/docker.sock We will be performing a baseline-scan in a CI/CD environment as it is ideal: sudo docker run --rm -d -u zap --name owasp-zap -v ~/:/zap/wrk/ owasp/zap2docker-stable zap-baseline.py -t http://192.168.1.55:8080 -r zap-report.html -l PASS Docker files used: --rm to remove container after completion. -d to run as a background job. -u to specify user to run container as. -v to 'host dir':'container dir', mount volumes. Zap CLI flags used: -t 'target' to specify target to scan. -r 'file.html' to generate an HTML output report. -l level to minimum level to show: PASS, IGNORE, INFO, WARN or FAIL. To run a fullscan script, run the following command: sudo docker run --rm -d -u zap --name owasp-zap -v ~/:/zap/wrk/ owasp/zap2docker-stable zap-full-scan.py -t http://192.168.1.55:8080 -r zap-report.html -l PASS The report created zap-report.html will be saved in the home directory after successfull completion! DAST Pipeline Finally, I added the script to the jenkins file to perform DAST on DVNA: stage('ZAP Scan') { steps { sh 'docker run --rm -i -u zap --name owasp-zap -v ~/reports/:/zap/wrk/ owasp/zap2docker-stable zap-baseline.py -t http://192.168.1.55:8080 -r zap-report.html -l PASS || true' } }","title":"Dynamic Analysis"},{"location":"DAST/#dynamic-analysis","text":"Objective The aim of this section is to perform dynamic analysis using DAST tools on DVNA and solve the 6th point of the Problem Statement .","title":"Dynamic Analysis"},{"location":"DAST/#what-is-dast","text":"Dynamic application security testing (DAST) is the process of testing and evaluating a program while software is running. Also referred to as dynamic code scanning, dynamic analysis improves the diagnosis and correction of bugs, memory issues, and crashes of an application during its execution.","title":"What is DAST"},{"location":"DAST/#why-is-dynamic-analysis-needed","text":"DAST is a method of AppSec testing that examines an application while it\u2019s running, without knowledge of the application\u2019s internal interactions or designs at the system level, and with no access or visibility into the source program. This \u201cblack box\u201d testing looks at an application from the outside in, examines its running state, and observes its responses to simulated attacks made by the tool. An application\u2019s responses to these simulations help determine whether the application is vulnerable and could be susceptible to a real malicious attack.","title":"Why is Dynamic Analysis Needed?"},{"location":"DAST/#static-vs-dynamic-analysis","text":"Static code analysis is done by examining the code without the need to execute the program. The process provides an understanding of the code structure and can help ensure that the code adheres to industry standards. All code is scanned to check for any vulnerabilities and ensure the code is validated. Dynamic analysis adopts the opposite approach and is executed while a program is in operation. Dynamic analysis performs continuous and concurrent risk assessments, searching for vulnerabilities within web applications and speeding interventions.","title":"Static Vs Dynamic Analysis"},{"location":"DAST/#owasp-zap","text":"ZAP is an open source tool which is offered by OWASP (Open Web Application Security Project), for penetration testing of your website/web application. It helps you find the security vulnerabilities in your application. ZAP creates a proxy server and makes your website traffic pass through that server. It comprises of auto scanners that help you intercept the vulnerabilities in your website. I followed the official documentation and pulled the ZAP image from docker: docker pull owasp/zap2docker-stable I got an permission denied error, and resolved it by changing the permissions as below: sudo chmod 666 /var/run/docker.sock We will be performing a baseline-scan in a CI/CD environment as it is ideal: sudo docker run --rm -d -u zap --name owasp-zap -v ~/:/zap/wrk/ owasp/zap2docker-stable zap-baseline.py -t http://192.168.1.55:8080 -r zap-report.html -l PASS Docker files used: --rm to remove container after completion. -d to run as a background job. -u to specify user to run container as. -v to 'host dir':'container dir', mount volumes. Zap CLI flags used: -t 'target' to specify target to scan. -r 'file.html' to generate an HTML output report. -l level to minimum level to show: PASS, IGNORE, INFO, WARN or FAIL. To run a fullscan script, run the following command: sudo docker run --rm -d -u zap --name owasp-zap -v ~/:/zap/wrk/ owasp/zap2docker-stable zap-full-scan.py -t http://192.168.1.55:8080 -r zap-report.html -l PASS The report created zap-report.html will be saved in the home directory after successfull completion!","title":"OWASP ZAP"},{"location":"DAST/#dast-pipeline","text":"Finally, I added the script to the jenkins file to perform DAST on DVNA: stage('ZAP Scan') { steps { sh 'docker run --rm -i -u zap --name owasp-zap -v ~/reports/:/zap/wrk/ owasp/zap2docker-stable zap-baseline.py -t http://192.168.1.55:8080 -r zap-report.html -l PASS || true' } }","title":"DAST Pipeline"},{"location":"Problem-statements/","text":"Problem Statements Setup the infrastructure, required for the task, on two virtual machines running locally on a laptop. One VM contains the Jenkins and related infrastructure, and the second VM is for deploying DVNA using the pipeline. Setup the Jenkins server and to know about Jenkins pipeline. Setup the MKDocs and Netlify, connect it to github repository. Deploy the DVNA in the production server. Perform static analysis by using suitable SAST tools on DVNA and generate a report. Getting to know Software Composition Analysis. Perform dynamic analysis by using suitable DAST tools on DVNA and generate a report. Generate Software Bill of Materials of DVNA for all its dependencies. Perform Source Code Quality Analysis for linting errors to improve code quality and generate quality report. Create a complete pipeline structure combining all the segments together. Do extensive documentation in markdown and deploy it as a MkDocs website.","title":"Problem Statements"},{"location":"Problem-statements/#problem-statements","text":"Setup the infrastructure, required for the task, on two virtual machines running locally on a laptop. One VM contains the Jenkins and related infrastructure, and the second VM is for deploying DVNA using the pipeline. Setup the Jenkins server and to know about Jenkins pipeline. Setup the MKDocs and Netlify, connect it to github repository. Deploy the DVNA in the production server. Perform static analysis by using suitable SAST tools on DVNA and generate a report. Getting to know Software Composition Analysis. Perform dynamic analysis by using suitable DAST tools on DVNA and generate a report. Generate Software Bill of Materials of DVNA for all its dependencies. Perform Source Code Quality Analysis for linting errors to improve code quality and generate quality report. Create a complete pipeline structure combining all the segments together. Do extensive documentation in markdown and deploy it as a MkDocs website.","title":"Problem Statements"},{"location":"Resources/","text":"Resources These are some references I used along with the ones mentioned implicitly in the report: Ubuntu - https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-18-04 OpenJDK (https://www.digitalocean.com/community/tutorials/how-to-install-java-with-apt-on-ubuntu-18-04#installing-specific-versions-of-openjdk) MKDocs (https://www.mkdocs.org/user-guide/installation/) Apache Maven (https://maven.apache.org/) NodeJS (https://docs.docker.com/engine/install/) Jenkins (https://www.digitalocean.com/community/tutorials/how-to-install-jenkins-on-ubuntu-18-04) DVNA (https://github.com/appsecco/dvna/blob/master/docs/setup.md) Docker Installation (https://docs.docker.com/engine/install/ubuntu/) NPM Installation (https://www.tecmint.com/install-nodejs-npm-in-centos-ubuntu/) njsscan (https://github.com/ajinabraham/njsscan) Auditjs (https://github.com/sonatype-nexus-community/auditjs) OWASP Dependancy Check (https://owasp.org/www-project-dependency-check/) ZAP docker (https://www.zaproxy.org/docs/docker/about/) ZAP docker baseline-scan (https://www.zaproxy.org/docs/docker/baseline-scan/) JSHint (https://jshint.com/docs/cli/, https://github.com/jshint/jshint) ESLint (https://eslint.org/docs/user-guide/, https://github.com/eslint/eslint) SBoM (https://www.synopsys.com/blogs/software-security/software-bill-of-materials-bom/) Cyclonedx-bom (https://github.com/CycloneDX/cyclonedx-node-module#cyclonedx-nodejs-module)","title":"Resources"},{"location":"Resources/#resources","text":"These are some references I used along with the ones mentioned implicitly in the report: Ubuntu - https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-18-04 OpenJDK (https://www.digitalocean.com/community/tutorials/how-to-install-java-with-apt-on-ubuntu-18-04#installing-specific-versions-of-openjdk) MKDocs (https://www.mkdocs.org/user-guide/installation/) Apache Maven (https://maven.apache.org/) NodeJS (https://docs.docker.com/engine/install/) Jenkins (https://www.digitalocean.com/community/tutorials/how-to-install-jenkins-on-ubuntu-18-04) DVNA (https://github.com/appsecco/dvna/blob/master/docs/setup.md) Docker Installation (https://docs.docker.com/engine/install/ubuntu/) NPM Installation (https://www.tecmint.com/install-nodejs-npm-in-centos-ubuntu/) njsscan (https://github.com/ajinabraham/njsscan) Auditjs (https://github.com/sonatype-nexus-community/auditjs) OWASP Dependancy Check (https://owasp.org/www-project-dependency-check/) ZAP docker (https://www.zaproxy.org/docs/docker/about/) ZAP docker baseline-scan (https://www.zaproxy.org/docs/docker/baseline-scan/) JSHint (https://jshint.com/docs/cli/, https://github.com/jshint/jshint) ESLint (https://eslint.org/docs/user-guide/, https://github.com/eslint/eslint) SBoM (https://www.synopsys.com/blogs/software-security/software-bill-of-materials-bom/) Cyclonedx-bom (https://github.com/CycloneDX/cyclonedx-node-module#cyclonedx-nodejs-module)","title":"Resources"},{"location":"SAST/","text":"Static Analysis Objective The aim of this section is to perform static analysis on DVNA using SAST tools in a Jenkins pipeline and solve the 4th point of the Problem Statement . To start creating the Jenkins pipeline, login into the jenkin web interface. Working of pipeline In the Dashboard , create a New Item and enter a item name (e.g. dvna-pipeline ) and select pipeline and click OK . It was redirected to the configuration page. Here: Under general section: Gave description of the application being deployed. I checked the Discard old builds as they keep metadata related to old builds. Under pipeline section, I selected the defination dropdown to Pipeline script from SCM . In SCM dropdown I selected GIT , and gave the repository URL . Click Save to save and aplly the configurations. Go to Dashboard -> dvna-pipeline -> build now -> console output . Jenkinsfile Jenkinsfile is a text file that contains the definition of a Jenkins Pipeline and is checked into source control.The following are the contents of the Jenkinsfile which implements a continuous delivery pipeline: pipeline { agent any stages { stage ('Initialization') { steps { sh 'echo \"Starting the build!\"' } } stage ('Build') { environment { MYSQL_USER=\"dvna\" MYSQL_DATABASE=\"dvna\" MYSQL_PASSWORD=\"Prlokhande_5398\" MYSQL_RANDOM_ROOT_PASSWORD=\"yes\" MYSQL_HOST=\"mysql-db\" MYSQL_PORT=3306 } steps { sh 'echo \"MYSQL_USER=$MYSQL_USER\\nMYSQL_DATABASE=$MYSQL_DATABASE\\nMYSQL_PASSWORD=$MYSQL_PASSWORD\\nMYSQL_RANDOM_ROOT_PASSWORD=$MYSQL_RANDOM_ROOT_PASSWORD\\nMYSQL_HOST=$MYSQL_HOST\\nMYSQL_PORT=$MYSQL_PORT\" > ~/vars.env' sh 'docker run --rm -d --name dvna-mysql --env-file ~/vars.env mysql:5.7 tail -f /dev/null' sh 'docker run --rm -d --name dvna-app --env-file ~/vars.env --link dvna-mysql:mysql-db -p 9090:9090 appsecco/dvna' sh 'docker cp dvna-app:/app/ ~/' } } stage ('Remove DVNA from Jenkins') { steps { sh 'rm -rf ~/app' sh 'docker stop dvna-app && docker stop dvna-mysql' sh 'docker rmi appsecco/dvna' } } stage ('Deploy DVNA to Production') { steps { sh 'ssh -tt -o StrictHostKeyChecking=no prod-vm@192.168.1.55 \"docker stop dvna-app && docker stop dvna-mysql && docker rm dvna-app && docker rm dvna-mysql && docker rmi appsecco/dvna || true\"' sh 'scp ~/vars.env prod-vm@192.168.1.55:~/' sh 'ssh -tt -o StrictHostKeyChecking=no prod-vm@192.168.1.55 \"docker run -d --name dvna-mysql --env-file ~/vars.env mysql:5.7 tail -f /dev/null\"' sh 'ssh -tt -o StrictHostKeyChecking=no prod-vm@192.168.1.55 \"docker run -d --name dvna-app --env-file ~/vars.env --link dvna-mysql:mysql-db -p 9090:9090 appsecco/dvna\"' } } } } Stages The pipeline is divided into various stages based on the operations being performed, which are as follows: Initialization This is the first stage which is used to just display the start of the building stage. Build This stage contains the environment variables, in which vars.env file is created and for dvna-mysql container. dvna-app and dvna-mysql containers will run and will be copied into the home directory. Static and Dynamic Analysis All the stages that follow the Build Stage, except for the last two stages, are for performing static analysis and dynamic analysis on DVNA and later being stored in a folder reports in jenkins home directory. Remove DVNA from Jenkins After the scans are complete, the containers running in Jenkins VM are stopped and removed. Since we're working with a containerized application (DVNA), we need to perform tests on the latest available image on DockerHub. Hence, we remove the existing local appsecco/dvna docker image to avoid running a container with older release of the application image. On the other hand, you don't need to remove the mysql:5.7 image, since we require v5.7 and not the latest version. Deployment Finally, the satge deploy to dvna , operations are performed on VM over SSH which was configured previously. The two containers, dvna-app and dvna-mysql are run and successfully deployed. Static Application Security Testing(SAST) SAST is a testing methodology that analyses source code, byte code and binaries for bugs and design errors to find security vulnerabilities , before the application is compiled. SAST does not require a working application and can take place without code being executed. It helps developers identify vulnerabilities in the initial stages of development and quickly resolve issues without breaking builds or passing on vulnerabilities to the final release of the application. SAST Tools for Node.js Applications As given the name Damn Vulnerable Nodejs Application, it is quite obvious to figure the tech stack used, Nodejs is the server-side language used along with a SQL database. The following are the tools used to perform static analysis on Nodejs applications with steps to install and configure them with Jenkins. njsscan njsscan is a open source static security code scanner for Node.js applications. Finds insecure paatterns in Node.js code and HTML templates. The tool is written in python, we need to install it using pip3, I went ahead and updated apt package and installed python3-pip. sudo apt update && sudo apt install python3-pip Intall,njsscan using pip3: pip3 install njsscan NOTE : I got an error while installing through njsscan, I entered into the root directory and installed it, which worked for me or you can also create a virtual environment and install it. I referred the documentation which provides us command line options . Later, I added the script in the jenkinsfile with the following syntax: mkdir reports njsscan -o ~/reports/nodejsscan-report.json --json ./dvna njsscan pipeline I added the following stage in the Jenkinsfile to perform the scan, and store the report in JSON format on the Jenkins machine: stage('NodeJsScan') { steps { sh 'njsscan --json -o ~/reports/nodejsscan-report ~/app || true' } } AuditJS Audits JavaScript is a SAST tool which uses OSS Index v3 REST API to identify known vulnerabilities and outdated package versions. To install npm and nodejs in dvna container in production server, I followed the commandsas given below, the package versions are: npm v6.14.14 and nodejs v14.17.4. sudo apt update sudo curl -sL https://deb.nodesource.com/setup_14.x | sudo -E bash - sudo apt install -y nodejs Install auditjs using npm: sudo npm install -g auditjs Scan the directory which holds the files for DVNA and store the scan result in ~/reports/auditjs-report. auditjs ossi > ~/reports/auditjs-report ./app AuditJS pipeline Finally, I added the following stage to the Jenkinsfile to execute the script I wrote: stage('Auditjs') { steps { sh 'cd ~/app; auditjs ossi > ~/reports/auditjs-report || true' } } SAST Pipeline Add the following stages to the Jenkinsfile for performing SAST of DVNA: stage('NodeJsScan') { steps { sh 'njsscan --json -o ~/reports/nodejsscan-report ~/app || true' } } stage('Auditjs') { steps { sh 'cd ~/app; auditjs ossi > ~/reports/auditjs-report || true' } }","title":"Static Analysis"},{"location":"SAST/#static-analysis","text":"Objective The aim of this section is to perform static analysis on DVNA using SAST tools in a Jenkins pipeline and solve the 4th point of the Problem Statement . To start creating the Jenkins pipeline, login into the jenkin web interface.","title":"Static Analysis"},{"location":"SAST/#working-of-pipeline","text":"In the Dashboard , create a New Item and enter a item name (e.g. dvna-pipeline ) and select pipeline and click OK . It was redirected to the configuration page. Here: Under general section: Gave description of the application being deployed. I checked the Discard old builds as they keep metadata related to old builds. Under pipeline section, I selected the defination dropdown to Pipeline script from SCM . In SCM dropdown I selected GIT , and gave the repository URL . Click Save to save and aplly the configurations. Go to Dashboard -> dvna-pipeline -> build now -> console output .","title":"Working of pipeline"},{"location":"SAST/#jenkinsfile","text":"Jenkinsfile is a text file that contains the definition of a Jenkins Pipeline and is checked into source control.The following are the contents of the Jenkinsfile which implements a continuous delivery pipeline: pipeline { agent any stages { stage ('Initialization') { steps { sh 'echo \"Starting the build!\"' } } stage ('Build') { environment { MYSQL_USER=\"dvna\" MYSQL_DATABASE=\"dvna\" MYSQL_PASSWORD=\"Prlokhande_5398\" MYSQL_RANDOM_ROOT_PASSWORD=\"yes\" MYSQL_HOST=\"mysql-db\" MYSQL_PORT=3306 } steps { sh 'echo \"MYSQL_USER=$MYSQL_USER\\nMYSQL_DATABASE=$MYSQL_DATABASE\\nMYSQL_PASSWORD=$MYSQL_PASSWORD\\nMYSQL_RANDOM_ROOT_PASSWORD=$MYSQL_RANDOM_ROOT_PASSWORD\\nMYSQL_HOST=$MYSQL_HOST\\nMYSQL_PORT=$MYSQL_PORT\" > ~/vars.env' sh 'docker run --rm -d --name dvna-mysql --env-file ~/vars.env mysql:5.7 tail -f /dev/null' sh 'docker run --rm -d --name dvna-app --env-file ~/vars.env --link dvna-mysql:mysql-db -p 9090:9090 appsecco/dvna' sh 'docker cp dvna-app:/app/ ~/' } } stage ('Remove DVNA from Jenkins') { steps { sh 'rm -rf ~/app' sh 'docker stop dvna-app && docker stop dvna-mysql' sh 'docker rmi appsecco/dvna' } } stage ('Deploy DVNA to Production') { steps { sh 'ssh -tt -o StrictHostKeyChecking=no prod-vm@192.168.1.55 \"docker stop dvna-app && docker stop dvna-mysql && docker rm dvna-app && docker rm dvna-mysql && docker rmi appsecco/dvna || true\"' sh 'scp ~/vars.env prod-vm@192.168.1.55:~/' sh 'ssh -tt -o StrictHostKeyChecking=no prod-vm@192.168.1.55 \"docker run -d --name dvna-mysql --env-file ~/vars.env mysql:5.7 tail -f /dev/null\"' sh 'ssh -tt -o StrictHostKeyChecking=no prod-vm@192.168.1.55 \"docker run -d --name dvna-app --env-file ~/vars.env --link dvna-mysql:mysql-db -p 9090:9090 appsecco/dvna\"' } } } }","title":"Jenkinsfile"},{"location":"SAST/#stages","text":"The pipeline is divided into various stages based on the operations being performed, which are as follows:","title":"Stages"},{"location":"SAST/#initialization","text":"This is the first stage which is used to just display the start of the building stage.","title":"Initialization"},{"location":"SAST/#build","text":"This stage contains the environment variables, in which vars.env file is created and for dvna-mysql container. dvna-app and dvna-mysql containers will run and will be copied into the home directory.","title":"Build"},{"location":"SAST/#static-and-dynamic-analysis","text":"All the stages that follow the Build Stage, except for the last two stages, are for performing static analysis and dynamic analysis on DVNA and later being stored in a folder reports in jenkins home directory.","title":"Static and Dynamic Analysis"},{"location":"SAST/#remove-dvna-from-jenkins","text":"After the scans are complete, the containers running in Jenkins VM are stopped and removed. Since we're working with a containerized application (DVNA), we need to perform tests on the latest available image on DockerHub. Hence, we remove the existing local appsecco/dvna docker image to avoid running a container with older release of the application image. On the other hand, you don't need to remove the mysql:5.7 image, since we require v5.7 and not the latest version.","title":"Remove DVNA from Jenkins"},{"location":"SAST/#deployment","text":"Finally, the satge deploy to dvna , operations are performed on VM over SSH which was configured previously. The two containers, dvna-app and dvna-mysql are run and successfully deployed.","title":"Deployment"},{"location":"SAST/#static-application-security-testingsast","text":"SAST is a testing methodology that analyses source code, byte code and binaries for bugs and design errors to find security vulnerabilities , before the application is compiled. SAST does not require a working application and can take place without code being executed. It helps developers identify vulnerabilities in the initial stages of development and quickly resolve issues without breaking builds or passing on vulnerabilities to the final release of the application.","title":"Static Application Security Testing(SAST)"},{"location":"SAST/#sast-tools-for-nodejs-applications","text":"As given the name Damn Vulnerable Nodejs Application, it is quite obvious to figure the tech stack used, Nodejs is the server-side language used along with a SQL database. The following are the tools used to perform static analysis on Nodejs applications with steps to install and configure them with Jenkins.","title":"SAST Tools for Node.js Applications"},{"location":"SAST/#njsscan","text":"njsscan is a open source static security code scanner for Node.js applications. Finds insecure paatterns in Node.js code and HTML templates. The tool is written in python, we need to install it using pip3, I went ahead and updated apt package and installed python3-pip. sudo apt update && sudo apt install python3-pip Intall,njsscan using pip3: pip3 install njsscan NOTE : I got an error while installing through njsscan, I entered into the root directory and installed it, which worked for me or you can also create a virtual environment and install it. I referred the documentation which provides us command line options . Later, I added the script in the jenkinsfile with the following syntax: mkdir reports njsscan -o ~/reports/nodejsscan-report.json --json ./dvna","title":"njsscan"},{"location":"SAST/#njsscan-pipeline","text":"I added the following stage in the Jenkinsfile to perform the scan, and store the report in JSON format on the Jenkins machine: stage('NodeJsScan') { steps { sh 'njsscan --json -o ~/reports/nodejsscan-report ~/app || true' } }","title":"njsscan pipeline"},{"location":"SAST/#auditjs","text":"Audits JavaScript is a SAST tool which uses OSS Index v3 REST API to identify known vulnerabilities and outdated package versions. To install npm and nodejs in dvna container in production server, I followed the commandsas given below, the package versions are: npm v6.14.14 and nodejs v14.17.4. sudo apt update sudo curl -sL https://deb.nodesource.com/setup_14.x | sudo -E bash - sudo apt install -y nodejs Install auditjs using npm: sudo npm install -g auditjs Scan the directory which holds the files for DVNA and store the scan result in ~/reports/auditjs-report. auditjs ossi > ~/reports/auditjs-report ./app","title":"AuditJS"},{"location":"SAST/#auditjs-pipeline","text":"Finally, I added the following stage to the Jenkinsfile to execute the script I wrote: stage('Auditjs') { steps { sh 'cd ~/app; auditjs ossi > ~/reports/auditjs-report || true' } }","title":"AuditJS pipeline"},{"location":"SAST/#sast-pipeline","text":"Add the following stages to the Jenkinsfile for performing SAST of DVNA: stage('NodeJsScan') { steps { sh 'njsscan --json -o ~/reports/nodejsscan-report ~/app || true' } } stage('Auditjs') { steps { sh 'cd ~/app; auditjs ossi > ~/reports/auditjs-report || true' } }","title":"SAST Pipeline"},{"location":"SBoM/","text":"What is SBoM? Objective The aim of this section is to perform dynamic analysis using DAST tools on DVNA and solve the 6th point of the Problem Statement . A software bill of materials is a list of all the open source and third-party components present in a codebase. A Bill of Materials is a list of components used to assemble/create a product. It gives out a specification about how each component was used in the making of the end product. CycloneDX To generate the SBoM for DVNA, we are using a tool called CycloneDX. According to the documentation CycloneDX is a module for Node.js creates a valid CycloneDX SBoM containing an aggregate of all project dependencies. SCA tools can discover all related components, their supporting libraries, and their direct and indirect dependencies. SCA tools can also detect software licenses, deprecated dependencies, as well as vulnerabilities and potential exploits. The scanning process generates a component inventory or software bill of materials (SBoM) , providing a complete inventory of a project\u2019s software assets which is then compared against a variety of databases, these databases hold information regarding known and common vulnerabilities. Generating SBoM for DVNA Here, I installed CycloneDX's Node module with NPM by using the command: sudo su npm install -g @cyclonedx/bom Later, I generated SBoM report in an .xml format(you can either generate using .xml or .json ) also use -o to specify filename and format(i.e., .xml) cyclonedx-bom -o sbom.xml SBoM pipeline Lastly, I added a stage in the pipeline to run CycloneDX and store the SBoM (sbom.xml) in the local reports folder: stage ('Generating Software Bill of Materials') { steps { sh 'cd ~/app && cyclonedx-bom -o ~/reports/sbom.xml' } }","title":"What is SBoM?"},{"location":"SBoM/#what-is-sbom","text":"Objective The aim of this section is to perform dynamic analysis using DAST tools on DVNA and solve the 6th point of the Problem Statement . A software bill of materials is a list of all the open source and third-party components present in a codebase. A Bill of Materials is a list of components used to assemble/create a product. It gives out a specification about how each component was used in the making of the end product.","title":"What is SBoM?"},{"location":"SBoM/#cyclonedx","text":"To generate the SBoM for DVNA, we are using a tool called CycloneDX. According to the documentation CycloneDX is a module for Node.js creates a valid CycloneDX SBoM containing an aggregate of all project dependencies. SCA tools can discover all related components, their supporting libraries, and their direct and indirect dependencies. SCA tools can also detect software licenses, deprecated dependencies, as well as vulnerabilities and potential exploits. The scanning process generates a component inventory or software bill of materials (SBoM) , providing a complete inventory of a project\u2019s software assets which is then compared against a variety of databases, these databases hold information regarding known and common vulnerabilities.","title":"CycloneDX"},{"location":"SBoM/#generating-sbom-for-dvna","text":"Here, I installed CycloneDX's Node module with NPM by using the command: sudo su npm install -g @cyclonedx/bom Later, I generated SBoM report in an .xml format(you can either generate using .xml or .json ) also use -o to specify filename and format(i.e., .xml) cyclonedx-bom -o sbom.xml","title":"Generating SBoM for DVNA"},{"location":"SBoM/#sbom-pipeline","text":"Lastly, I added a stage in the pipeline to run CycloneDX and store the SBoM (sbom.xml) in the local reports folder: stage ('Generating Software Bill of Materials') { steps { sh 'cd ~/app && cyclonedx-bom -o ~/reports/sbom.xml' } }","title":"SBoM pipeline"},{"location":"Source-Code-Quality-Analysis/","text":"Software Code Quality Analysis Source Code Linting Lint, or a linter, is a source code analysis tool used to flag programming errors, bugs, stylistic errors, and suspicious constructs. Linter's are used to generate reports about the code quality by either invoking a built-in functionality or writing a reporting wrapper arround the tool to resolve the identified issues. Linting tools for DVNA DVNA is a Nodejs application and hence, I used JSHint and ESLint as the linter. JSHint scans your program's source code and reports about commonly made mistakes and potential bugs. The potential problem could be a syntax error, a bug due to implicit type conversion, a leaking variable, or any of the other problems that JSHint looks for and it is a command-line utility, I can easily integrate it into my CI pipeline with Jenkins. Integrating JSHint with Jenkins pipeline I installed it globally with NPM using the following command: sudo npm install -g jshint Run the jshint command with the aplication/project directory to scan all the .js files as given below: jshint ~/app > ~/report/jshint-report The above command will scan all the files in the directory. To restrict the scan to only .js and .ejs files, use a find command. We will further exclude all files in the node_modules directory. jshint $(find ~/app -type f -name \" .js\" -o -name \" .ejs\" | grep -v node_modules) > ~/reports/jshint-report JSHint Pipeline stage ('JSHint Analysis') { steps { sh 'jshint $(find ~/app -type f \\( -name \"*.js\" -o -name \"*.ejs\" \\) | grep -v node_modules) > ~/reports/jshint-report || true' } } ESLint ESLint is a static code analysis tool for identifying problematic patterns found in JavaScript code. ESLint covers both code quality and coding style issues.Unlike JSHint, ESLint uses Espree for JavaScript parsing and an AST to evaluate patterns in code. It's completely pluggable, every single rule is a plugin and you can add more at runtime. I followed the official documentation to install ESLint using NPM: npm install -g eslint Now, to run the scan eslint requires a .eslintrc configuration file which contains environment variables, rules and other configuration details. To create this file, run eslint --init in the project's root folder you will be prompted with a few questions to create the config file, and the responses are as shown below: \u2714 How would you like to use ESLint? \u00b7 problems \u2714 What type of modules does your project use? \u00b7 commonjs \u2714 Which framework does your project use? \u00b7 none \u2714 Does your project use TypeScript? \u00b7 No \u2714 Where does your code run? \u00b7 browser \u2714 What format do you want your config file to be in? \u00b7 JSON NOTE : The .eslintrc.json config file is required everytime I run an eslint scan on a file or directory.It's not possible to create the config file by running eslint --init as the command line waits for responses to file configuration questions. To resolve this problem, copy the configuration details shown above into <Jenkins-Home-Dir>/.eslintrc.json file. You can now specify eslint to use this config file during its execution. The contents of the .eslintrc.json file are as below: { \"env\": { \"browser\": true, \"commonjs\": true, \"es2021\": true }, \"extends\": \"eslint:recommended\", \"parserOptions\": { \"ecmaVersion\": 12 }, \"rules\": { } } To perform an eslint scan, run eslint command with the following flags: - -c to specify the config file. - -f to format of output report. - --ext to specify the extensions of files to be scannned. - -o to specify file to write the report to a particular file. eslint -c ~/.eslintrc.json -f html --ext .js,.ejs -o ~/reports/eslint-report.html ~/app ESLint Pipeline Finally, I added a stage in the pipeline to run the script after I made it executable. The stage that I added was as follows: stage ('ESLint Analysis') { steps { sh 'eslint -c ~/.eslintrc.json -f html --ext .js,.ejs -o ~/reports/eslint-report.html ~/app || true' } }","title":"Source Code Quality Analysis"},{"location":"Source-Code-Quality-Analysis/#software-code-quality-analysis","text":"","title":"Software Code Quality Analysis"},{"location":"Source-Code-Quality-Analysis/#source-code-linting","text":"Lint, or a linter, is a source code analysis tool used to flag programming errors, bugs, stylistic errors, and suspicious constructs. Linter's are used to generate reports about the code quality by either invoking a built-in functionality or writing a reporting wrapper arround the tool to resolve the identified issues.","title":"Source Code Linting"},{"location":"Source-Code-Quality-Analysis/#linting-tools-for-dvna","text":"DVNA is a Nodejs application and hence, I used JSHint and ESLint as the linter. JSHint scans your program's source code and reports about commonly made mistakes and potential bugs. The potential problem could be a syntax error, a bug due to implicit type conversion, a leaking variable, or any of the other problems that JSHint looks for and it is a command-line utility, I can easily integrate it into my CI pipeline with Jenkins.","title":"Linting tools for DVNA"},{"location":"Source-Code-Quality-Analysis/#integrating-jshint-with-jenkins-pipeline","text":"I installed it globally with NPM using the following command: sudo npm install -g jshint Run the jshint command with the aplication/project directory to scan all the .js files as given below: jshint ~/app > ~/report/jshint-report The above command will scan all the files in the directory. To restrict the scan to only .js and .ejs files, use a find command. We will further exclude all files in the node_modules directory. jshint $(find ~/app -type f -name \" .js\" -o -name \" .ejs\" | grep -v node_modules) > ~/reports/jshint-report","title":"Integrating JSHint with Jenkins pipeline"},{"location":"Source-Code-Quality-Analysis/#jshint-pipeline","text":"stage ('JSHint Analysis') { steps { sh 'jshint $(find ~/app -type f \\( -name \"*.js\" -o -name \"*.ejs\" \\) | grep -v node_modules) > ~/reports/jshint-report || true' } }","title":"JSHint Pipeline"},{"location":"Source-Code-Quality-Analysis/#eslint","text":"ESLint is a static code analysis tool for identifying problematic patterns found in JavaScript code. ESLint covers both code quality and coding style issues.Unlike JSHint, ESLint uses Espree for JavaScript parsing and an AST to evaluate patterns in code. It's completely pluggable, every single rule is a plugin and you can add more at runtime. I followed the official documentation to install ESLint using NPM: npm install -g eslint Now, to run the scan eslint requires a .eslintrc configuration file which contains environment variables, rules and other configuration details. To create this file, run eslint --init in the project's root folder you will be prompted with a few questions to create the config file, and the responses are as shown below: \u2714 How would you like to use ESLint? \u00b7 problems \u2714 What type of modules does your project use? \u00b7 commonjs \u2714 Which framework does your project use? \u00b7 none \u2714 Does your project use TypeScript? \u00b7 No \u2714 Where does your code run? \u00b7 browser \u2714 What format do you want your config file to be in? \u00b7 JSON NOTE : The .eslintrc.json config file is required everytime I run an eslint scan on a file or directory.It's not possible to create the config file by running eslint --init as the command line waits for responses to file configuration questions. To resolve this problem, copy the configuration details shown above into <Jenkins-Home-Dir>/.eslintrc.json file. You can now specify eslint to use this config file during its execution. The contents of the .eslintrc.json file are as below: { \"env\": { \"browser\": true, \"commonjs\": true, \"es2021\": true }, \"extends\": \"eslint:recommended\", \"parserOptions\": { \"ecmaVersion\": 12 }, \"rules\": { } } To perform an eslint scan, run eslint command with the following flags: - -c to specify the config file. - -f to format of output report. - --ext to specify the extensions of files to be scannned. - -o to specify file to write the report to a particular file. eslint -c ~/.eslintrc.json -f html --ext .js,.ejs -o ~/reports/eslint-report.html ~/app","title":"ESLint"},{"location":"Source-Code-Quality-Analysis/#eslint-pipeline","text":"Finally, I added a stage in the pipeline to run the script after I made it executable. The stage that I added was as follows: stage ('ESLint Analysis') { steps { sh 'eslint -c ~/.eslintrc.json -f html --ext .js,.ejs -o ~/reports/eslint-report.html ~/app || true' } }","title":"ESLint Pipeline"},{"location":"contents/","text":"Table of contents Introduction Problem Statements Setting up VMs Setting up jenkins Setting up mkdocs Setting up pipeline Setting up dvna Static Analysis Software Composition Analysis Dynamic Analysis Source Code Quality Analysis Complete Pipeline Resources","title":"Contents"},{"location":"contents/#table-of-contents","text":"Introduction Problem Statements Setting up VMs Setting up jenkins Setting up mkdocs Setting up pipeline Setting up dvna Static Analysis Software Composition Analysis Dynamic Analysis Source Code Quality Analysis Complete Pipeline Resources","title":"Table of contents"},{"location":"setting-up-VM/","text":"Setting up VMs Objective This section aims to set up the required infrastructure to perform the task and solve the 1st point of the Problem Statement . What is Virtual Machine? For understanding Virtual machine (VM) we will have to understand what Virtualization is. Virtualization is a software based or virtual version of something, that be compute, storage, networking, servers or applications. And Hypervisor makes Virtualization possible. Hypervisor is a piece of software that runs above host or server. There are 2 types of hypervisors: Type 1: It is installed directly on top of physical server. Type 2: Here there is a layer of Host operating system (OS) between the hardware and Hypervisor (as we are using here). A VM is an OS or application environment that is installed on software, which imitates dedicated physical server. A VM provides an isolated environment for running its own OS and applications independently from the underlying host system or from other VMs on that host. The VM's OS is commonly referred to as the guest OS, and it can be the same as or different from the host OS or the other VMs. Setting up VM Here I will be setting up two VMs: For Jenkins Deployment. For DVNA server. In virtual Box Click on NEW icon to create a new machine. Later follow the steps as given below: Name and operating system Name : Jenkins-deploy Type : Linux Version : Ubuntu (64-bit) Memory size Select 2000 MB and click on create . Hard disk Select a virtual hard disk now and Create and Hard disk file type will open in that select VDI (VirtualBox Disk Image) and NEXT . In storage on physical hard disk select Dynamically allocated file location and size will open hit Create and is done. Download server image 18.04 Downloaded the server image Ubuntu 18.04 on VirtualBox as it is an LTS version which is a desirable feature for a CI pipeline. I followed the official link to download the 64-bit PC(AMD64) desktop image. In VM box I selected Jenkins-deploy to install the server and then clicked on start . Then the Select start-up disk window opened and I clicked on the folder which gave a new screen Optical Disk Selector . I selected the server image and clicked on Choose . Here, I clicked on start . Now Jenkins VM starts running! Language selection After successfully installtion the b language selection dialogue box will opwn and here select the language English and click on done . Keyboard configuration By default, English is selected for Layout and variant, clicked on Done . Network connections I kept it as default and selected Done . Configure proxy The proxy configured on this screen is used for accessing the package repository and the snap store both in the installer environment and in the installed system. I did not provide any Proxy address, kept it default and selected Done . Configure ubuntu archive mirror The installer will attempt to use GeoIP to lookup an appropriate default package mirror for your location. I kept this too as default and selected Done . Storage configuration I did not make changes in the storage configuration I kept it as default and clicked on Done . I kept this too as default and hit Done . Profile setup I provided all the details and clicked on Done . SSH Setup In order to install the OpenSSH server I selected the Install OpenSSH server option because by default ubuntu won't have openSSH installed, and then I kept Import SSH identity as default and clicked on Done . Featured Server Snaps Selected the snaps which are useful in a server environment, once selected clicked on Done . Installation complete Installation complete window appeared, wait until the Reboot button appears on this window. Later, select reboot . And the installation of Ubuntu 18.04 is completed! Repeat the same process in order to create another VM for DVNA deployment where I have specified the server name as DVNA-deploy .","title":"Setting up VMs"},{"location":"setting-up-VM/#setting-up-vms","text":"Objective This section aims to set up the required infrastructure to perform the task and solve the 1st point of the Problem Statement .","title":"Setting up VMs"},{"location":"setting-up-VM/#what-is-virtual-machine","text":"For understanding Virtual machine (VM) we will have to understand what Virtualization is. Virtualization is a software based or virtual version of something, that be compute, storage, networking, servers or applications. And Hypervisor makes Virtualization possible. Hypervisor is a piece of software that runs above host or server. There are 2 types of hypervisors: Type 1: It is installed directly on top of physical server. Type 2: Here there is a layer of Host operating system (OS) between the hardware and Hypervisor (as we are using here). A VM is an OS or application environment that is installed on software, which imitates dedicated physical server. A VM provides an isolated environment for running its own OS and applications independently from the underlying host system or from other VMs on that host. The VM's OS is commonly referred to as the guest OS, and it can be the same as or different from the host OS or the other VMs.","title":"What is Virtual Machine?"},{"location":"setting-up-VM/#setting-up-vm","text":"Here I will be setting up two VMs: For Jenkins Deployment. For DVNA server. In virtual Box Click on NEW icon to create a new machine. Later follow the steps as given below:","title":"Setting up VM"},{"location":"setting-up-VM/#name-and-operating-system","text":"Name : Jenkins-deploy Type : Linux Version : Ubuntu (64-bit)","title":"Name and operating system"},{"location":"setting-up-VM/#memory-size","text":"Select 2000 MB and click on create .","title":"Memory size"},{"location":"setting-up-VM/#hard-disk","text":"Select a virtual hard disk now and Create and Hard disk file type will open in that select VDI (VirtualBox Disk Image) and NEXT . In storage on physical hard disk select Dynamically allocated file location and size will open hit Create and is done.","title":"Hard disk"},{"location":"setting-up-VM/#download-server-image-1804","text":"Downloaded the server image Ubuntu 18.04 on VirtualBox as it is an LTS version which is a desirable feature for a CI pipeline. I followed the official link to download the 64-bit PC(AMD64) desktop image. In VM box I selected Jenkins-deploy to install the server and then clicked on start . Then the Select start-up disk window opened and I clicked on the folder which gave a new screen Optical Disk Selector . I selected the server image and clicked on Choose . Here, I clicked on start . Now Jenkins VM starts running!","title":"Download server image 18.04"},{"location":"setting-up-VM/#language-selection","text":"After successfully installtion the b language selection dialogue box will opwn and here select the language English and click on done .","title":"Language selection"},{"location":"setting-up-VM/#keyboard-configuration","text":"By default, English is selected for Layout and variant, clicked on Done .","title":"Keyboard configuration"},{"location":"setting-up-VM/#network-connections","text":"I kept it as default and selected Done .","title":"Network connections"},{"location":"setting-up-VM/#configure-proxy","text":"The proxy configured on this screen is used for accessing the package repository and the snap store both in the installer environment and in the installed system. I did not provide any Proxy address, kept it default and selected Done .","title":"Configure proxy"},{"location":"setting-up-VM/#configure-ubuntu-archive-mirror","text":"The installer will attempt to use GeoIP to lookup an appropriate default package mirror for your location. I kept this too as default and selected Done .","title":"Configure ubuntu archive mirror"},{"location":"setting-up-VM/#storage-configuration","text":"I did not make changes in the storage configuration I kept it as default and clicked on Done . I kept this too as default and hit Done .","title":"Storage configuration"},{"location":"setting-up-VM/#profile-setup","text":"I provided all the details and clicked on Done .","title":"Profile setup"},{"location":"setting-up-VM/#ssh-setup","text":"In order to install the OpenSSH server I selected the Install OpenSSH server option because by default ubuntu won't have openSSH installed, and then I kept Import SSH identity as default and clicked on Done .","title":"SSH Setup"},{"location":"setting-up-VM/#featured-server-snaps","text":"Selected the snaps which are useful in a server environment, once selected clicked on Done .","title":"Featured Server Snaps"},{"location":"setting-up-VM/#installation-complete","text":"Installation complete window appeared, wait until the Reboot button appears on this window. Later, select reboot . And the installation of Ubuntu 18.04 is completed! Repeat the same process in order to create another VM for DVNA deployment where I have specified the server name as DVNA-deploy .","title":"Installation complete"},{"location":"setting-up-dvna/","text":"Configuring Production VM Objective The aim of this section is to configure DVNA in a Production server as mentioned in the Problem Statement . What is DVNA Damn Vulnerable NodeJS Application (DVNA) is a simple NodeJS application to demonstrate OWASP Top 10 Vulnerabilities and guide on fixing and avoiding these vulnerabilities Requirements To serve DVNA, there are some prerequisites: - VM running Ubuntu 18.04 LTS. - Docker, NodeJS and NPM Install Docker, NodeJS and NPM For Docker installation I referred the official documentation , update the apt package index: sudo apt-get update Add Docker\u2019s official GPG key: curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg Use the following command to set up the stable repository: echo \\ \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null Update the apt package index, and install the latest version of Docker Engine and containerd, or go to the next step to install a specific version: sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io sudo docker run hello-world # Test if docker installation is successful Install NodeJS and NPM: sudo curl -sL https://deb.nodesource.com/setup_14.x | sudo -E bash - && sudo apt install -y nodejs Setup DVNA I followed the official documentation for setup. Create a file named vars.env with the following configuration: MYSQL_USER=dvna MYSQL_DATABASE=dvna MYSQL_PASSWORD=passw0rd MYSQL_RANDOM_ROOT_PASSWORD=yes MYSQL_HOST=mysql-db MYSQL_PORT=3306 Start a MySQL container, unless you want to use your own, in which case configure in the env file above. docker run --name dvna-mysql --env-file vars.env -d mysql:5.7 Start the application using the official image: docker run --name dvna-app --env-file vars.env --link dvna-mysql:mysql-db -p 9090:9090 appsecco/dvna To test if the containers are running, run docker ps -a you will see two containers running dvna-app and dvna-mysql and docker stop for stopping the container. Access the application at http://your-ip-address:8080.","title":"Setting up DVNA"},{"location":"setting-up-dvna/#configuring-production-vm","text":"Objective The aim of this section is to configure DVNA in a Production server as mentioned in the Problem Statement .","title":"Configuring Production VM"},{"location":"setting-up-dvna/#what-is-dvna","text":"Damn Vulnerable NodeJS Application (DVNA) is a simple NodeJS application to demonstrate OWASP Top 10 Vulnerabilities and guide on fixing and avoiding these vulnerabilities","title":"What is DVNA"},{"location":"setting-up-dvna/#requirements","text":"To serve DVNA, there are some prerequisites: - VM running Ubuntu 18.04 LTS. - Docker, NodeJS and NPM","title":"Requirements"},{"location":"setting-up-dvna/#install-docker-nodejs-and-npm","text":"For Docker installation I referred the official documentation , update the apt package index: sudo apt-get update Add Docker\u2019s official GPG key: curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg Use the following command to set up the stable repository: echo \\ \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null Update the apt package index, and install the latest version of Docker Engine and containerd, or go to the next step to install a specific version: sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io sudo docker run hello-world # Test if docker installation is successful Install NodeJS and NPM: sudo curl -sL https://deb.nodesource.com/setup_14.x | sudo -E bash - && sudo apt install -y nodejs","title":"Install Docker, NodeJS and NPM"},{"location":"setting-up-dvna/#setup-dvna","text":"I followed the official documentation for setup. Create a file named vars.env with the following configuration: MYSQL_USER=dvna MYSQL_DATABASE=dvna MYSQL_PASSWORD=passw0rd MYSQL_RANDOM_ROOT_PASSWORD=yes MYSQL_HOST=mysql-db MYSQL_PORT=3306 Start a MySQL container, unless you want to use your own, in which case configure in the env file above. docker run --name dvna-mysql --env-file vars.env -d mysql:5.7 Start the application using the official image: docker run --name dvna-app --env-file vars.env --link dvna-mysql:mysql-db -p 9090:9090 appsecco/dvna To test if the containers are running, run docker ps -a you will see two containers running dvna-app and dvna-mysql and docker stop for stopping the container. Access the application at http://your-ip-address:8080.","title":"Setup DVNA"},{"location":"setting-up-jenkins/","text":"Setting up Jenkins Objective This section aims to set up the required infrastructure of Jenkins to perform the task and solve the 2nd point of the Problem Statement . What is Jenkins? Jenkins is a self-contained, open-source automation server which can be used to automate all sorts of tasks related to building, testing, and delivering or deploying software. Installation steps for Jenkins Prerequisite I have setup ubuntu 18.04 VM, installing Jenkins from Documentation . I have installed java 8 OpenJDK and JRE (Java Development Kit and Java Runtime Environment) which is used to develop and run the software, I have used this Link to download the same. Add the repository key to the terminal: wget -q -O - https://pkg.jenkins.io/debian-stable/jenkins.io.key | sudo apt-key add - The system will return OK Next, add the Debian package repository address: sudo sh -c 'echo deb https://pkg.jenkins.io/debian-stable binary/ > \\ /etc/apt/sources.list.d/jenkins.list sudo apt update Now install Jenkins and it\u2019s dependencies: sudo apt install jenkins Starting Jenkins The systemctl command is used to manage \"systemd\" services and service manager: sudo systemctl start jenkins Check the status of Jenkins service using the below command: sudo systemctl status jenkins And the Jenkins has installed successfully, the output is showing as Active: active(excited) . To reach it from a web browser I will adjust the firewall rules to complete the initial setup. Set-up a Firewall with UFW Firewall is a software controlling incoming and outgoing network traffic. Firewall is able to manage traffic by monitoring network ports. By default, Jenkins runs on port 8080. And opening the using ufw(uncomplicated firewall): sudo ufw allow 8080 To check the status of the ufw: sudo ufw status If the status shows \"Inactive\". Then enable using following command : sudo ufw enable To configure your server to allow incoming SSH connections, you can use this command: sudo ufw allow ssh Setting up Jenkins To find your server's ip address or domain name enter the following command in your terminal: ifconfig Using the server's name or domain name as shown in the following command, entering that into a browser inturn gave the Unlock Jenkins window. http://your_server_name_or_domain:8080 Unlock Jenkins The Unlock Jenkins window shows where the admin password is stored. In the terminal I will use the cat command to display the password: sudo cat /var/lib/jenkins/secrets/initialAdminPassword The 32-character alphanumeric password is displayed in the terminal, paste it onto Administrator password field, and then click on continue . Customize Jenkins In the Customize Jenkins select install suggested plugins which will start installation process directly and click on continue . Create Admin User Add the required credentials, click on save and continue as admin. The Instance configuration page will be displayed which will ask to confirm the preferred URL for Jenkins instance, click on save and finish . Installation Starts Once the process is over click on Reboot which will restart the Jenkins. Now the Jenkins is running Successfully, now typing the below command become the Jenkins user: sudo su - jenkins","title":"Setting up Jenkins"},{"location":"setting-up-jenkins/#setting-up-jenkins","text":"Objective This section aims to set up the required infrastructure of Jenkins to perform the task and solve the 2nd point of the Problem Statement .","title":"Setting up Jenkins"},{"location":"setting-up-jenkins/#what-is-jenkins","text":"Jenkins is a self-contained, open-source automation server which can be used to automate all sorts of tasks related to building, testing, and delivering or deploying software.","title":"What is Jenkins?"},{"location":"setting-up-jenkins/#installation-steps-for-jenkins","text":"","title":"Installation steps for Jenkins"},{"location":"setting-up-jenkins/#prerequisite","text":"I have setup ubuntu 18.04 VM, installing Jenkins from Documentation . I have installed java 8 OpenJDK and JRE (Java Development Kit and Java Runtime Environment) which is used to develop and run the software, I have used this Link to download the same. Add the repository key to the terminal: wget -q -O - https://pkg.jenkins.io/debian-stable/jenkins.io.key | sudo apt-key add - The system will return OK Next, add the Debian package repository address: sudo sh -c 'echo deb https://pkg.jenkins.io/debian-stable binary/ > \\ /etc/apt/sources.list.d/jenkins.list sudo apt update Now install Jenkins and it\u2019s dependencies: sudo apt install jenkins","title":"Prerequisite"},{"location":"setting-up-jenkins/#starting-jenkins","text":"The systemctl command is used to manage \"systemd\" services and service manager: sudo systemctl start jenkins Check the status of Jenkins service using the below command: sudo systemctl status jenkins And the Jenkins has installed successfully, the output is showing as Active: active(excited) . To reach it from a web browser I will adjust the firewall rules to complete the initial setup.","title":"Starting Jenkins"},{"location":"setting-up-jenkins/#set-up-a-firewall-with-ufw","text":"Firewall is a software controlling incoming and outgoing network traffic. Firewall is able to manage traffic by monitoring network ports. By default, Jenkins runs on port 8080. And opening the using ufw(uncomplicated firewall): sudo ufw allow 8080 To check the status of the ufw: sudo ufw status If the status shows \"Inactive\". Then enable using following command : sudo ufw enable To configure your server to allow incoming SSH connections, you can use this command: sudo ufw allow ssh","title":"Set-up a Firewall with UFW"},{"location":"setting-up-jenkins/#setting-up-jenkins_1","text":"To find your server's ip address or domain name enter the following command in your terminal: ifconfig Using the server's name or domain name as shown in the following command, entering that into a browser inturn gave the Unlock Jenkins window. http://your_server_name_or_domain:8080","title":"Setting up Jenkins"},{"location":"setting-up-jenkins/#unlock-jenkins","text":"The Unlock Jenkins window shows where the admin password is stored. In the terminal I will use the cat command to display the password: sudo cat /var/lib/jenkins/secrets/initialAdminPassword The 32-character alphanumeric password is displayed in the terminal, paste it onto Administrator password field, and then click on continue .","title":"Unlock Jenkins"},{"location":"setting-up-jenkins/#customize-jenkins","text":"In the Customize Jenkins select install suggested plugins which will start installation process directly and click on continue .","title":"Customize Jenkins"},{"location":"setting-up-jenkins/#create-admin-user","text":"Add the required credentials, click on save and continue as admin. The Instance configuration page will be displayed which will ask to confirm the preferred URL for Jenkins instance, click on save and finish .","title":"Create Admin User"},{"location":"setting-up-jenkins/#installation-starts","text":"Once the process is over click on Reboot which will restart the Jenkins. Now the Jenkins is running Successfully, now typing the below command become the Jenkins user: sudo su - jenkins","title":"Installation Starts"},{"location":"setting-up-mkdocs/","text":"Setting up MKDocs Objective This section aims to create documentation in Markdown and use MkDocs to deploy the documentation generated as a static site and solve the 3rd point of the Problem Statement . What is MKDocs MkDocs is a static site generator that's geared towards building project documentation. Documentation source files are written in Markdown, and configured with a single YAML configuration file. MkDocs will build your docs and used to commit and push them to GitHub. Installing MKDocs I have installed MKDocs using the official Documentation If you need to install pip for the first time, download get-pip.py by running the following command: python get-pip.py Install the MKDocs package using: pip insatll mkdocs Later, check the version of the MKDocs installed in order to check everything worked okay. mkdocs --version Selecting a Theme In order to customize a theme, I referred official Documentation from MkDocs themes. Here I preferred Material theme, to use this particular theme it needs to be installed via pip. pip install mkdocs-material Configuration Create a new project to store all the documentation as given in below commands: mkdocs new my-project cd my-project After creating a folder in VScode, create a file named mkdocs.yml and a folder named docs . The index.md file is created in docs folder which contains a single documentation page. In mkdocs.yml include: site_name: 'DevSecOps-pipeline' nav: Introduction: 'index.md' Contents: 'contents.md' Setting up VM: 'setting-up-VM.md' Setting up Jenkins: 'setting-up-jenkins.md' Setting up mkDocs: 'setting-up-mkdocs.md' theme: material Here we have mentioned the site name as DevSecOps-pipeline which is the title of the site, in the nav include all the contents which are explained throughout the documentation and the theme needs to be mentioned here. Push code to GitHub Here, I made a repository initially as DevSecOps-Internship also checked the option private repository and then create repository . In a terminal, I ran: git init mkdocs build git add . git commit -m \"Initial commit\" git push -u origin master Later, I checked the repository all the files where committed successfully. Building the MKDocs site Building a site converts the documented files into a HTML and CSS format and will the files in a folder named site within the same directory which contains mkdocs.yml file. In the terminal I ran a following command from parent directory: mkdocs build --clean Deploy on Netlify Created a account in netlify . Selected Add a new project option. A window will open which asks for Connect to git provider . Select Create a new site and later select Github . Select the repository you need to publish, I selected DevSecOps-pipeline. later select the repository and a window will appear under that add site/ in publish directory. Click on Deploy site and the site will be deployed and the link will be available on top of the screen. Change the name of the site, as default it will be having dummy name (in my case it is devsecops-pipeline ).","title":"Setting up mkDocs"},{"location":"setting-up-mkdocs/#setting-up-mkdocs","text":"Objective This section aims to create documentation in Markdown and use MkDocs to deploy the documentation generated as a static site and solve the 3rd point of the Problem Statement .","title":"Setting up MKDocs"},{"location":"setting-up-mkdocs/#what-is-mkdocs","text":"MkDocs is a static site generator that's geared towards building project documentation. Documentation source files are written in Markdown, and configured with a single YAML configuration file. MkDocs will build your docs and used to commit and push them to GitHub.","title":"What is MKDocs"},{"location":"setting-up-mkdocs/#installing-mkdocs","text":"I have installed MKDocs using the official Documentation If you need to install pip for the first time, download get-pip.py by running the following command: python get-pip.py Install the MKDocs package using: pip insatll mkdocs Later, check the version of the MKDocs installed in order to check everything worked okay. mkdocs --version","title":"Installing MKDocs"},{"location":"setting-up-mkdocs/#selecting-a-theme","text":"In order to customize a theme, I referred official Documentation from MkDocs themes. Here I preferred Material theme, to use this particular theme it needs to be installed via pip. pip install mkdocs-material","title":"Selecting a Theme"},{"location":"setting-up-mkdocs/#configuration","text":"Create a new project to store all the documentation as given in below commands: mkdocs new my-project cd my-project After creating a folder in VScode, create a file named mkdocs.yml and a folder named docs . The index.md file is created in docs folder which contains a single documentation page. In mkdocs.yml include: site_name: 'DevSecOps-pipeline' nav: Introduction: 'index.md' Contents: 'contents.md' Setting up VM: 'setting-up-VM.md' Setting up Jenkins: 'setting-up-jenkins.md' Setting up mkDocs: 'setting-up-mkdocs.md' theme: material Here we have mentioned the site name as DevSecOps-pipeline which is the title of the site, in the nav include all the contents which are explained throughout the documentation and the theme needs to be mentioned here.","title":"Configuration"},{"location":"setting-up-mkdocs/#push-code-to-github","text":"Here, I made a repository initially as DevSecOps-Internship also checked the option private repository and then create repository . In a terminal, I ran: git init mkdocs build git add . git commit -m \"Initial commit\" git push -u origin master Later, I checked the repository all the files where committed successfully.","title":"Push code to GitHub"},{"location":"setting-up-mkdocs/#building-the-mkdocs-site","text":"Building a site converts the documented files into a HTML and CSS format and will the files in a folder named site within the same directory which contains mkdocs.yml file. In the terminal I ran a following command from parent directory: mkdocs build --clean","title":"Building the MKDocs site"},{"location":"setting-up-mkdocs/#deploy-on-netlify","text":"Created a account in netlify . Selected Add a new project option. A window will open which asks for Connect to git provider . Select Create a new site and later select Github . Select the repository you need to publish, I selected DevSecOps-pipeline. later select the repository and a window will appear under that add site/ in publish directory. Click on Deploy site and the site will be deployed and the link will be available on top of the screen. Change the name of the site, as default it will be having dummy name (in my case it is devsecops-pipeline ).","title":"Deploy on Netlify"},{"location":"setting-up-pipeline/","text":"Jenkins Pipeline Objective The aim of this section is to understand the Jenkins pipeline to deploy DVNA and solve the 4rth point of the Problem Statement . Why use Jenkins pipeline ? Jenkins is an open continuous integration server which has the ability to support the automation of software development processes. You can create multiple automation jobs with the help of use cases, and run them as a Jenkins pipeline. Here are the reasons why you use should use Jenkins pipeline: Jenkins pipeline is implemented as a code which allows multiple users to edit and execute the pipeline process. Pipelines are robust. So, if your server undergoes an unforeseen restart, the pipeline will be automatically resumed. You can pause the pipeline process and make it wait to resume until there is an input from the user. Jenkins Pipelines support big projects. You can run multiple jobs, and even use pipelines in a loop. Setup Jenkins Pipeline Here, we are using Apache Maven as a plugin which is a software project management and comprehension tool. Based on the concept of a project object model (POM), Maven can manage a project's build, reporting and documentation from a central piece of information. Jenkins provides a particular job type, which explicitly provides options for configuring and executing a Maven project. This job type is called the Maven project Let\u2019s see how we can create a Maven project in Jenkins and run the same. Install Maven Plugin in Jenkins Click on the Manage Jenkins -> System Configuration -> Manage Plugins options. Under the Plugin Manager, click on the Available tab and search for the maven plugin. It will show the Maven Integration plugin as a result and check the checkbox and select install without restart . Once the plugin installs successfully, click the checkbox to restart Jenkins. After the restart of Jenkins, the Maven Jenkins plugin will be installed successfully and ready for configuration. Create A Maven project in Jenkins. In the Dashboard , create a New Item . Now, enter item name as Jenkin-Maven and selct Maven project as shown below and click on OK . Here, under general section: I gave the description of the project. Under Source Code Management I checked the Git option and provided the Github URl . This helps jenkins to know where to fetch the project from. Under Build Triggers : I checked Build whenever a SNAPSHOT dependency is built this is convenient for automatically performing continuous integration. Jenkins will check the snapshot dependencies from the dependency element in the POM, as well as plugins and extensions used in POMs. Later, clicked on save button. What is Jenkinsfile? Jenkins Pipeline has a customizable and scalable automation system that lets you build distribution pipeline scripts - \u201cPipeline as Code\u201d, these scripts are called JenkinsFile. A JenkinsFile stores the entire CI/CD process as code on the local machine. As such, the file can be reviewed and checked into a Source Code Management (SCM) platform (be it Git or SVN) along with your code. Hence, the term \u201cPipeline as Code\u201d. The structure of my jenkinsfile is as follows: pipeline { agent any stages { stage ('Compile Stage') { steps { withMaven(maven : 'maven_3_6_0') { sh 'mvn clean compile' } } } stage ('Testing Stage') { steps { withMaven(maven : 'maven_3_6_0') { sh 'mvn test' } } } stage ('Deployment Stage') { steps { withMaven(maven : 'maven_3_6_0') { sh 'mvn deploy' } } } } } pipeline - Constitutes the entire definition of the pipeline. agent - Is used to choose the way the Jenkins instance(s) are used to run the pipeline. The any keyword defines that Jenkins should - allocate any available agent (an instance of Jenkins/a slave/the master instance) to execute the pipeline. stages - Consists of all the stages/jobs to be performed during the execution of the pipeline. stage - Specify the task to be performed. steps - This block defines actions to be performed within a particular stage. sh - Used to execute shell commands through Jenkins. SSH Access Configuration Secure Shell Protocol (SSH) provides a secure channel over an unsecured network by using a client\u2013server architecture, connecting an SSH client application with an SSH server. The standard TCP port for SSH is 22. Installation In order to SSH into VM we need to install it! sudo apt-get install openssh-server Enable the ssh service by: sudo systemctl enable ssh Start the ssh service: sudo systemctl start ssh SSH into VM After installing SSH, create a key pair on a client machine. ssh-keygen -t ed25519 The first prompt from the ssh-keygen command will ask you where to save the keys, I pressed enter to save as it was. Similarly, Creating passphrase just pressed enter . Once the key is generated, place the public key on the server which you want to connect to. Following the command below: ssh-copy-id username@your_server_address While copying the id I got an error \"cannot create .ssh/ authorized keys permission denied\", so I changed the permissions of the authorized_keys file and the folder/parent folders in which it is located. chmod 700 ~/.ssh chmod 600 ~/.ssh/authorized_keys - Also, I changed the permissions of home directory to remove write access for the group and others. chmod go-w ~ Now, I tried ssh'ing into the VM and it worked! ssh username@server_ip_address I got an error saying permission denied, I refered this documentation and did the necessary changes which are: sudo nano /etc/ssh/sshd_config - Changed the permissions as below: PermitRootLogin yes PasswordAuthentication yes And don't forget to reload: sudo systemctl restart ssh.service Setup SSH keys for Jenkins In the jenkins web control panel, install the plugin Publish Over SSH and nagivate to Manage Jenkins -> Configure System -> Publish over SSH . Either enter the path of the file e.g. var/lib/jenkins/.ssh/id_rsa , or add the private SSH key to the input field. Add SSH server details. Give the Production servers hostname (IP address), username for logging in and remote directory (/home/prod-vm)","title":"Setting up pipeline"},{"location":"setting-up-pipeline/#jenkins-pipeline","text":"Objective The aim of this section is to understand the Jenkins pipeline to deploy DVNA and solve the 4rth point of the Problem Statement .","title":"Jenkins Pipeline"},{"location":"setting-up-pipeline/#why-use-jenkins-pipeline","text":"Jenkins is an open continuous integration server which has the ability to support the automation of software development processes. You can create multiple automation jobs with the help of use cases, and run them as a Jenkins pipeline. Here are the reasons why you use should use Jenkins pipeline: Jenkins pipeline is implemented as a code which allows multiple users to edit and execute the pipeline process. Pipelines are robust. So, if your server undergoes an unforeseen restart, the pipeline will be automatically resumed. You can pause the pipeline process and make it wait to resume until there is an input from the user. Jenkins Pipelines support big projects. You can run multiple jobs, and even use pipelines in a loop.","title":"Why use Jenkins pipeline ?"},{"location":"setting-up-pipeline/#setup-jenkins-pipeline","text":"Here, we are using Apache Maven as a plugin which is a software project management and comprehension tool. Based on the concept of a project object model (POM), Maven can manage a project's build, reporting and documentation from a central piece of information. Jenkins provides a particular job type, which explicitly provides options for configuring and executing a Maven project. This job type is called the Maven project Let\u2019s see how we can create a Maven project in Jenkins and run the same.","title":"Setup Jenkins Pipeline"},{"location":"setting-up-pipeline/#install-maven-plugin-in-jenkins","text":"Click on the Manage Jenkins -> System Configuration -> Manage Plugins options. Under the Plugin Manager, click on the Available tab and search for the maven plugin. It will show the Maven Integration plugin as a result and check the checkbox and select install without restart . Once the plugin installs successfully, click the checkbox to restart Jenkins. After the restart of Jenkins, the Maven Jenkins plugin will be installed successfully and ready for configuration.","title":"Install Maven Plugin in Jenkins"},{"location":"setting-up-pipeline/#create-a-maven-project-in-jenkins","text":"In the Dashboard , create a New Item . Now, enter item name as Jenkin-Maven and selct Maven project as shown below and click on OK . Here, under general section: I gave the description of the project. Under Source Code Management I checked the Git option and provided the Github URl . This helps jenkins to know where to fetch the project from. Under Build Triggers : I checked Build whenever a SNAPSHOT dependency is built this is convenient for automatically performing continuous integration. Jenkins will check the snapshot dependencies from the dependency element in the POM, as well as plugins and extensions used in POMs. Later, clicked on save button.","title":"Create A Maven project in Jenkins."},{"location":"setting-up-pipeline/#what-is-jenkinsfile","text":"Jenkins Pipeline has a customizable and scalable automation system that lets you build distribution pipeline scripts - \u201cPipeline as Code\u201d, these scripts are called JenkinsFile. A JenkinsFile stores the entire CI/CD process as code on the local machine. As such, the file can be reviewed and checked into a Source Code Management (SCM) platform (be it Git or SVN) along with your code. Hence, the term \u201cPipeline as Code\u201d. The structure of my jenkinsfile is as follows: pipeline { agent any stages { stage ('Compile Stage') { steps { withMaven(maven : 'maven_3_6_0') { sh 'mvn clean compile' } } } stage ('Testing Stage') { steps { withMaven(maven : 'maven_3_6_0') { sh 'mvn test' } } } stage ('Deployment Stage') { steps { withMaven(maven : 'maven_3_6_0') { sh 'mvn deploy' } } } } } pipeline - Constitutes the entire definition of the pipeline. agent - Is used to choose the way the Jenkins instance(s) are used to run the pipeline. The any keyword defines that Jenkins should - allocate any available agent (an instance of Jenkins/a slave/the master instance) to execute the pipeline. stages - Consists of all the stages/jobs to be performed during the execution of the pipeline. stage - Specify the task to be performed. steps - This block defines actions to be performed within a particular stage. sh - Used to execute shell commands through Jenkins.","title":"What is Jenkinsfile?"},{"location":"setting-up-pipeline/#ssh-access-configuration","text":"Secure Shell Protocol (SSH) provides a secure channel over an unsecured network by using a client\u2013server architecture, connecting an SSH client application with an SSH server. The standard TCP port for SSH is 22.","title":"SSH Access Configuration"},{"location":"setting-up-pipeline/#installation","text":"In order to SSH into VM we need to install it! sudo apt-get install openssh-server Enable the ssh service by: sudo systemctl enable ssh Start the ssh service: sudo systemctl start ssh","title":"Installation"},{"location":"setting-up-pipeline/#ssh-into-vm","text":"After installing SSH, create a key pair on a client machine. ssh-keygen -t ed25519 The first prompt from the ssh-keygen command will ask you where to save the keys, I pressed enter to save as it was. Similarly, Creating passphrase just pressed enter . Once the key is generated, place the public key on the server which you want to connect to. Following the command below: ssh-copy-id username@your_server_address While copying the id I got an error \"cannot create .ssh/ authorized keys permission denied\", so I changed the permissions of the authorized_keys file and the folder/parent folders in which it is located. chmod 700 ~/.ssh chmod 600 ~/.ssh/authorized_keys - Also, I changed the permissions of home directory to remove write access for the group and others. chmod go-w ~ Now, I tried ssh'ing into the VM and it worked! ssh username@server_ip_address I got an error saying permission denied, I refered this documentation and did the necessary changes which are: sudo nano /etc/ssh/sshd_config - Changed the permissions as below: PermitRootLogin yes PasswordAuthentication yes And don't forget to reload: sudo systemctl restart ssh.service","title":"SSH into VM"},{"location":"setting-up-pipeline/#setup-ssh-keys-for-jenkins","text":"In the jenkins web control panel, install the plugin Publish Over SSH and nagivate to Manage Jenkins -> Configure System -> Publish over SSH . Either enter the path of the file e.g. var/lib/jenkins/.ssh/id_rsa , or add the private SSH key to the input field. Add SSH server details. Give the Production servers hostname (IP address), username for logging in and remote directory (/home/prod-vm)","title":"Setup SSH keys for Jenkins"},{"location":"software-composition-analysis/","text":"Software composition analysis Objective The aim of this section is to configure DVNA in a Production server as mentioned in the Problem Statement . What is SCA Software composition analysis (SCA) identifies all the open source in a codebase and maps that inventory to a list of current known vulnerabilities. It helps identify vulnerabilities in open source code (dependencies) used in code. SCA is the process of automating the visibility into open source software (OSS) use for the purpose of risk management, security and license compliance. With the rise of open source (OS) use in software across all industries, the need to track components increases exponentially to protect companies from issues and open source vulnerabilities. OWASP Depedency-Check Dependency-Check is a Software Composition Analysis (SCA) tool that attempts to detect publicly disclosed vulnerabilities contained within a project\u2019s dependencies. It does this by determining if there is a Common Platform Enumeration (CPE) identifier for a given dependency. If found, it will generate a report linking to the associated CVE entries. Performing SCA in DVNA I followed the official documentation in order to download the Dependency-Check CLI and the associated GPG signature file which is given below: wget -P ~/ https://github.com/jeremylong/DependencyCheck/releases/download/v6.2.2/dependency-check-6.2.2-release.zip wget -P ~/ https://github.com/jeremylong/DependencyCheck/releases/download/v6.2.2/dependency-check-6.2.2-release.zip.asc Now, extract the files from dependency-check tool zip file: unzip ~/dependency-check-6.2.2-release.zip Perform the scan by specifying the path to the project, output report format and its location: ~/dependency-check/bin/dependency-check.sh --scan ~/app --out ~/report/dependency-check-report --format JSON --prettyPrint SCA Pipeline NOTE : While adding the script to the pipeline I got an error: It was an DNS error, I went ahead and resolved it by the folleing command in the <jenkins-home-dir> : sudo dhclient enp0s3 Finally, I added the script to the jenkinsfile to perform SCA of DVNA: stage ('OWASP Dependency-Check') { steps { sh '~/dependency-check/bin/dependency-check.sh --scan ~/app --out ~/reports/dependency-check-report --format JSON --prettyPrint || true' } }","title":"Software Composition Analysis"},{"location":"software-composition-analysis/#software-composition-analysis","text":"Objective The aim of this section is to configure DVNA in a Production server as mentioned in the Problem Statement .","title":"Software composition analysis"},{"location":"software-composition-analysis/#what-is-sca","text":"Software composition analysis (SCA) identifies all the open source in a codebase and maps that inventory to a list of current known vulnerabilities. It helps identify vulnerabilities in open source code (dependencies) used in code. SCA is the process of automating the visibility into open source software (OSS) use for the purpose of risk management, security and license compliance. With the rise of open source (OS) use in software across all industries, the need to track components increases exponentially to protect companies from issues and open source vulnerabilities.","title":"What is SCA"},{"location":"software-composition-analysis/#owasp-depedency-check","text":"Dependency-Check is a Software Composition Analysis (SCA) tool that attempts to detect publicly disclosed vulnerabilities contained within a project\u2019s dependencies. It does this by determining if there is a Common Platform Enumeration (CPE) identifier for a given dependency. If found, it will generate a report linking to the associated CVE entries.","title":"OWASP Depedency-Check"},{"location":"software-composition-analysis/#performing-sca-in-dvna","text":"I followed the official documentation in order to download the Dependency-Check CLI and the associated GPG signature file which is given below: wget -P ~/ https://github.com/jeremylong/DependencyCheck/releases/download/v6.2.2/dependency-check-6.2.2-release.zip wget -P ~/ https://github.com/jeremylong/DependencyCheck/releases/download/v6.2.2/dependency-check-6.2.2-release.zip.asc Now, extract the files from dependency-check tool zip file: unzip ~/dependency-check-6.2.2-release.zip Perform the scan by specifying the path to the project, output report format and its location: ~/dependency-check/bin/dependency-check.sh --scan ~/app --out ~/report/dependency-check-report --format JSON --prettyPrint","title":"Performing SCA in DVNA"},{"location":"software-composition-analysis/#sca-pipeline","text":"NOTE : While adding the script to the pipeline I got an error: It was an DNS error, I went ahead and resolved it by the folleing command in the <jenkins-home-dir> : sudo dhclient enp0s3 Finally, I added the script to the jenkinsfile to perform SCA of DVNA: stage ('OWASP Dependency-Check') { steps { sh '~/dependency-check/bin/dependency-check.sh --scan ~/app --out ~/reports/dependency-check-report --format JSON --prettyPrint || true' } }","title":"SCA Pipeline"}]}